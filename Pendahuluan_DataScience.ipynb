{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img alt=\"\" src=\"img/Cover_ScienCom.jpg\"/></center> \n",
    "<center><h1><strong>Dr. Taufik Sutanto, MScTech</strong></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"blue\">Outline:</font>\n",
    "\n",
    "* Pendahuluan (Introduction, Requirement, etc)\n",
    "* Pendahuluan DS, ML, AI, & BD\n",
    "* Exploratory Data Analysis\n",
    "* Supervised learning Regression\n",
    "* Evaluation and Interpretability\n",
    "* Supervised Learning Classifications\n",
    "* Complications: Imbalance, Rare Case, Concept Drift\n",
    "* Unsupervised Learning\n",
    "* Evaluations\n",
    "* Introduction to NLP & Text Mining\n",
    "* Application challenge\n",
    "* Social Network Analysis: Challenge and Opportunities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img alt=\"\" src=\"img/0_About.jpg\"/></center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img alt=\"\" src=\"img/0_myResearch.jpg\"/></center> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"blue\"> Hardware Requirements:</font>\n",
    "\n",
    "\n",
    "<ol>\n",
    "\t<li><strong>Python 3.6</strong> </li>\n",
    "\t<li>Beberapa fungsi di workshop ini <strong><font color=\"blue\">membutuhkan koneksi internet</font></strong> ketika di eksekusi.</li>\n",
    "\t<li>Dianjurkan peserta mengupdate OS (Windows/Linux) sebelum mengikuti workshop.</li>\n",
    "\t<li>Apple Macintosh <u><strong>tidak disarankan</strong></u> untuk digunakan untuk keperluan pengolahan data di Data Science/Machine Learning.</li>\n",
    "</ol>\n",
    "\n",
    "<p>Ekspektasi spesifikasi komputer:</p>\n",
    "\n",
    "<ol>\n",
    "\t<li><strong>OS</strong>: Windows/Linux/Mac <strong><font color=\"blue\">64bit</font></strong>... <em>with recent updates</em>.</li>\n",
    "\t<li><strong>RAM</strong>: 4Gb or More</li>\n",
    "\t<li><strong>CPU</strong>: minimum 1 Ghz</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"blue\">Workshop Requirements/Assumptions:</font>\n",
    "\n",
    "* Minor Statistics\n",
    "* Minor (any) programming\n",
    "* Dikarenakan keterbatasan waktu, tidak memungkinkan membahas semua aspek Data Science/Big Data\n",
    "* Mengingat keragaman latar belakang peserta, workshop lebih fokus ke contoh aplikasi\n",
    "* Disarankan (tidak wajib) menggunakan koneksi internet sendiri (**_mobile data_**). Karena beberapa fungsi di workshop akan lebih efektif jika koneksi berasal dari beberapa **_ip address_** yang berbeda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"blue\"> Google Colaboratory </font>\n",
    "\n",
    "* Cocok untuk komputer yang memiliki spesifikasi yang relatif minim dan atau OS yang digunakan Macintosh. \n",
    "* Karena semua perintah dijalankan di server Google (cloud), maka membutuhkan koneksi internet yang baik:\n",
    "1. Kunjungi https://bit.ly/sciencom-30okt2019\n",
    "2. Login dengan Username dan password Google (gmail)\n",
    "3. Codes sudah bisa dijalankan dengan memilih cell yang akan dijalankan, lalu menekan tombol \"ctrl+Enter\" di keyboard. Atau \"Tombol Play\" di HP/Mobile Phones/tablet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules untuk Notebook ini\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "import time, numpy as np, matplotlib.pyplot as plt, pandas as pd, seaborn as sns\n",
    "sns.set(style=\"ticks\", color_codes=True)\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import cluster, datasets\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from itertools import cycle, islice\n",
    "from sklearn.metrics import silhouette_score as siluet\n",
    "from sklearn.metrics.cluster import homogeneity_score as purity\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "random_state = 170\n",
    "# Importing Some Python Modules\n",
    "from scipy import stats\n",
    "!pip install imblearn\n",
    "from imblearn.datasets import make_imbalance\n",
    "from imblearn.under_sampling import NearMiss # underSampling\n",
    "from imblearn.over_sampling import SMOTE # OverSampling\n",
    "from imblearn.combine import SMOTEENN # Combination of the 2\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn import svm, preprocessing\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.datasets import make_blobs, make_moons, make_circles, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import model_selection\n",
    "from collections import Counter\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "# Importing Modules\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "try:\n",
    "    import TS_HardClustering as TS, umap\n",
    "except:\n",
    "    !pip install umap-learn\n",
    "    !wget https://raw.githubusercontent.com/taufikedys/ScienCom/master/TS_HardClustering.py # \"Google Colab\"\n",
    "    import TS_HardClustering as TS, umap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2>Tipe Data Stevens (1946, 1951)</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Tipe_Data_Stevens.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\">Tipe Data, recent trend: Data Tidak Terstruktur\n",
    "\n",
    "<center><img alt=\"\" src=\"img/tipeData_2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=\"blue\">Data Science\n",
    "\n",
    "<center><img alt=\"\" src=\"img/DataScience.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "* Diperkenalkan oleh John Tukey 1961: \" _Procedures for analyzing data, techniques for interpreting the results of such procedures, ways of planning the gathering of data to make its analysis easier, more precise or more accurate, and all the machinery and results of (mathematical) statistics which apply to analyzing data._\"\n",
    "* Tukey promoted the use of five number summary of numerical data—the two extremes (maximum and minimum), the median, and the quartiles.\n",
    "* EDA refers to the critical process of performing **initial investigations on data** so as to discover patterns,to spot **anomalies**,to test hypothesis and to **check assumptions** with the help of **summary statistics and graphical representations**.\n",
    "* Tools: Python, R, S-Plus, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tujuan EDA\n",
    "\n",
    "* **Suggest hypotheses** about the causes of observed phenomena\n",
    "* **Assess assumptions** on which statistical inference will be based\n",
    "* Support the **selection of appropriate statistical techniques**\n",
    "* Provide a basis for further data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/XII_desc_Stat.jpg\" style=\"width: 800px; height: 328px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/central_Tendency.png\" style=\"width: 600px; height: 377px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Central-Tendency-is-not-enough:-Dispersion-of-Data\">Central Tendency is not enough</h3>\n",
    "\n",
    "<video controls src=\"img/The_Need_for_Data_Disperity_.MP4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Dispersion-of-Data\">Dispersion of Data</h3>\n",
    "\n",
    "<ul>\n",
    "\t<li>&quot;Hanya&quot; CTM bisa menipu?</li>\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Data_Dispersions.png\" style=\"width: 500px; height: 284px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualizations\n",
    "<p><img alt=\"\" src=\"img/XII_data_visualizations.png\" style=\"width: 800px; height: 499px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exploratory Data Analysis\n",
    "<p><img alt=\"\" src=\"img/XII_data_analysis_EDA.png\" style=\"width: 646px; height: 550px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n",
    "* Mean/Modus; General or per category (better)\n",
    "* Predict\n",
    "* Exclude?\n",
    "* Missing at Random (MAR) or Not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values\n",
    "<p><img alt=\"\" src=\"img/XII_dealing_missing.png\" style=\"width: 622px; height: 544px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Noisy-Data\">Noisy Data</h3>\n",
    "\n",
    "<ul>\n",
    "\t<li>Noise: random error or variance in a measured variable</li>\n",
    "\t<li>Noise can happen because of<br />\n",
    "\t&bull;faulty data collection instruments<br />\n",
    "\t&bull;data entry mistakes<br />\n",
    "\t&bull;data transmission problems<br />\n",
    "\t&bull;inconsistency in naming convention</li>\n",
    "\t<li>Outliers are data objects with characteristics that are considerably different than most of the other data objects in the data set</li>\n",
    "\t<li>Different outliers<br />\n",
    "\t&bull;Valid: CEO&rsquo;s salary,<br />\n",
    "\t&bull;Noisy: One&rsquo;s age = 200, widely deviated points</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "* **Hati-hati Noise VS Outliers dan jumlahnya**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Duplicate Data\n",
    "<p><img alt=\"\" src=\"img/XII_Duplicate-Data.png\" style=\"width: 789px; height: 222px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Outliers\n",
    "* Asumsi Normal\n",
    "* Asumsi distribusi lain\n",
    "\n",
    "### Multivariate Outliers\n",
    "* Clustering (DBSCAN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Perbandingan beberapa metode pendeteksian outliers (multivariate):</strong></p>\n",
    "\n",
    "<ol>\n",
    "\t<li>&nbsp;<a href=\"http://scikit-learn.org/stable/auto_examples/applications/plot_outlier_detection_housing.html#sphx-glr-auto-examples-applications-plot-outlier-detection-housing-py&amp;nbsp\" target=\"_blank\">http://scikit-learn.org/stable/auto_examples/applications/plot_outlier_detection_housing.html#sphx-glr-auto-examples-applications-plot-outlier-detection-housing-py&amp;nbsp</a>;</li>\n",
    "\t<li><a href=\"http://scikit-learn.org/stable/auto_examples/covariance/plot_outlier_detection.html#sphx-glr-auto-examples-covariance-plot-outlier-detection-py\" target=\"_blank\">http://scikit-learn.org/stable/auto_examples/covariance/plot_outlier_detection.html#sphx-glr-auto-examples-covariance-plot-outlier-detection-py</a></li>\n",
    "\t<li><a href=\"http://scikit-learn.org/stable/auto_examples/neighbors/plot_lof.html#sphx-glr-auto-examples-neighbors-plot-lof-py\" target=\"_blank\">http://scikit-learn.org/stable/auto_examples/neighbors/plot_lof.html#sphx-glr-auto-examples-neighbors-plot-lof-py</a></li>\n",
    "\t<li><a href=\"http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py\" target=\"_blank\">http://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py</a></li>\n",
    "\t<li>https://blog.dominodatalab.com/topology-and-density-based-clustering/</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Warming-up-discussion:\">Warming up discussion:</h3>\n",
    "\n",
    "<ul>\n",
    "\t<li>Outliers deteksi?, Apa yang sebaiknya dilakukan? Mengapa?</li>\n",
    "\t<li>Noise: Apa yang disebut dengan noise? Deteksi? Apa yang harus dilakukan?</li>\n",
    "\t<li>Dimension reduction. Mengapa? Bagaimana caranya?</li>\n",
    "\t<li>Transformasi data. Mengapa? Fungsi Apa?</li>\n",
    "\t<li>duplikasi (row/column). Apa yang harus dilakukan? Mengapa?</li>\n",
    "\t<li>Variabel yang berkorelasi. Apa yang sebaiknya dilakukan? Mengapa?</li>\n",
    "\t<li>Missing Data. Apa yang sebaiknya dilakukan? Mengapa?</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studi Kasus 1\n",
    "\n",
    "* Misal seorang Data Scientist ditugaskan untuk menentukan investasi properti terbaik.\n",
    "* Tujuan analisa di modul ini adalah menemukan harga rumah yang lebih rendah dari harga pasaran\n",
    "* Asumsikan kita memiliki data harga rumah yang ditawarkan dan variabel-variabel terkait lainnya.\n",
    "* Untuk membuat keputusan investasi, kita akan melakukan EDA dan membuat pada data yang ada.\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Regression-model.jpg\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contoh Kasus Data Harga Property Rumah\n",
    "\n",
    "* Sumber Data: http://byebuyhome.com/\n",
    "* Objective: menemukan harga rumah yang berada di bawah pasaran.\n",
    "* Variable:\n",
    " - **Dist_Taxi** – distance to nearest taxi stand from the property\n",
    " - **Dist_Market** – distance to nearest grocery market from the property\n",
    " - **Dist_Hospital** – distance to nearest hospital from the property\n",
    " - **Carpet** – carpet area of the property in square feet\n",
    " - **Builtup** – built-up area of the property in square feet\n",
    " - **Parking** – type of car parking available with the property\n",
    " - **City_Category** – categorization of the city based on the size\n",
    " - **Rainfall** – annual rainfall in the area where property is located\n",
    " - **House_Price** – price at which the property was sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing CSV data  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "!wget https://raw.githubusercontent.com/taufikedys/ScienCom/master/data/price.csv\n",
    "price = pd.read_csv('price.csv')\n",
    "\n",
    "# Prefer XLS atau CSV di Data Science/Machine Learning ... Mengapa?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipe Datanya : DataFrame (df)\n",
    "type(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ukuran Data\n",
    "N, P = price.shape\n",
    "print('baris = ', N, ', Kolom = ', P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tipe data di setiap kolom\n",
    "# Wajib di periksa apakah tipe datanya sudah tepat?\n",
    "# Perhatikan df sebagaimana semua variable di Python diperlakukan seperti object\n",
    "price.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Mengintip\" beberapa data pertamanya\n",
    "\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Mengintip\" beberapa data akhirnya\n",
    "price.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chosen at random\n",
    "price.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing a variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop kolom pertama karena tidak berguna (hanya index)\n",
    "price.drop(\"Observation\", axis=1, inplace=True)\n",
    "price.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merubah tipe data \"jika\" tidak tepat, contoh:\n",
    "\n",
    "price.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe types: https://pbpython.com/pandas_dtypes.html\n",
    "price['Parking'] = price['Parking'].astype('category')\n",
    "price['City_Category'] = price['City_Category'].astype('category')\n",
    "price.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistika Deskriptif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistika Sederhana dari data \"Numerik\"-nya\n",
    "price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ini adalah parameter tambahan jika kita juga ingin mendapatkan statistik sederhana seluruh datanya\n",
    "# (termasuk data kategorik)\n",
    "price.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memilih hanya variable dengan tipe tertentu\n",
    "price_num = price.select_dtypes(include = ['float64', 'int64'])\n",
    "price_num.head()\n",
    "# Perhatikan price_num adalah variable df baru! ... (hati-hati di data yang besar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memilih hanya variable dengan tipe tertentu\n",
    "price_cat = price.select_dtypes(include = ['category'])\n",
    "price_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing some columns manually\n",
    "X = price[['House_Price','Dist_Market']] \n",
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribusi nilai pada setiap variabel kategorik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique values of a variable/column\n",
    "for col in price_cat.columns:\n",
    "    print(col,': ', set(price[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price\n",
    "# Jika yang dibutuhkan memang hanya nama kolom, maka kita bisa melakukan hal ini untuk menghemat penggunaan memory\n",
    "numVar = price.select_dtypes(include = ['float64', 'int64']).columns\n",
    "list(numVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribusi tiap data\n",
    "price.City_Category.value_counts()\n",
    "# kita bisa juga visualisasikan informasi ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6)) # https://matplotlib.org/api/_as_gen/matplotlib.pyplot.figure.html#matplotlib.pyplot.figure\n",
    "p = sns.countplot(x=\"City_Category\", data=price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ini dilakukan jika kita ingin menyimpan plotnya ke dalam suatu file\n",
    "p.figure.savefig(\"output_BarChart.png\")\n",
    "# lihat di folder ipynb-nya akan muncul file baru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PieChart\n",
    "plot = price.Parking.value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apakah ada kecenderungan perbedaan harga rumah akibat dari tipe tempat parkir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= sns.catplot(x=\"Parking\", y=\"House_Price\", data=price)\n",
    "# Apa yang bisa dilihat dari hasil ini?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier atau noise? How to decide?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Outlier removal\n",
    "\n",
    "### Perlu asumsi \"distribusi\" dari datanya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normality Assumption\n",
    "\n",
    "<p><img alt=\"\" src=\"img/XII_normal_CI.png\" style=\"width: 800px; height: 374px;\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions\n",
    "p = sns.distplot(price['House_Price'], kde=True, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misal dengan asumsi data berdistribusi normal\n",
    "# dan menggunakan 99% confidence interval di sekitar variabel \"harga\"\n",
    "\n",
    "price2 = price[np.abs(price.House_Price - price.House_Price.mean())<=(3*price.House_Price.std())] # Data tanpa outliers\n",
    "print(price2.shape, price.shape)\n",
    "# Perhatikan disini sengaja data yang telah di remove outliernya \n",
    "# disimpan dalam variabel baru \"Price2\"\n",
    "# Jika datanya besar hati-hati melakukan hal ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributions\n",
    "p = sns.distplot(price2['House_Price'], kde=True, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot lagi setelah outlier removal\n",
    "p= sns.catplot(x=\"Parking\", y=\"House_Price\", data=price2)\n",
    "# Apakah ada kecenderungan perbedaan harga rumah akibat dari tipe tempat parkir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bisa juga plot dengan informasi dari 3 variabel sekaligus\n",
    "# (untuk melihat kemungkinan faktor interaksi)\n",
    "\n",
    "p= sns.catplot(x=\"Parking\", y=\"House_Price\", hue=\"City_Category\", kind=\"swarm\", data=price2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada \"dugaan\" apakah dari hasil diatas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Look at the Missing Values\n",
    "print(price2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplest solution, if the MV is not a lot\n",
    "# drop rows with missing values : Ada berbagai cara\n",
    "X = price.dropna() # jika ada MV minimal satu di salah satu kolom, maka baris di hapus\n",
    "price2.dropna(how='all') # jika ada MV di semua kolom, maka baris di hapus\n",
    "price2.dropna(thresh=2) # jika ada MV minimal di salah 2 kolom, maka baris di hapus\n",
    "price2.dropna(subset=['Dist_Hospital'])[:7] # jika ada MV minimal satu di salah kolom Dist_Hospital\n",
    "# inplace=True if really really sure\n",
    "price2.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mengecek apakah ada duplikat data?\n",
    "print(price2.shape)\n",
    "price2.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#menghapus entri yang memiliki data duplikat \n",
    "price2.drop_duplicates(inplace=True)\n",
    "print(price2.duplicated().sum()) # no more duplicates\n",
    "print(price2.shape) # re-check by printing data size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (PairWise) Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plots; https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "p = sns.pairplot(price2, hue=\"City_Category\")\n",
    "# Warning agak lambat (variabel cukup banyak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coba kita perhatikan sebagiannya saja dulu dan coba kelompokkan berdasarkan \"Parking\"\n",
    "p = sns.pairplot(price2[['House_Price','Builtup','Dist_Hospital','Dist_Taxi','Parking']], hue=\"Parking\")\n",
    "# Ada pola menarik?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving (preprocessed) Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the preprocessed Data for future use/analysis\n",
    "price2.to_csv(\"data_01_pricing_PreProcessed.csv\", encoding='utf8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing DataFrame - Just like query in SQL\n",
    "price2[price2[\"Parking\"] == \"Covered\"].describe()\n",
    "# Bisa ditambahkan .drop(\"Parking\", axis=1) untuk menghilangkan kolom dengan single value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BoxPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BoxPlots\n",
    "p = sns.boxplot(x=\"House_Price\", y=\"Parking\", data=price2)\n",
    "# Apa makna pola yang terlihat di data oleh BoxPlot ini?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jika ada outlier grafiknya menjadi tidak jelas (data = price, bukan price2)\n",
    "p = sns.boxplot(x=\"House_Price\", y=\"Parking\", data=price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boxplot dapat juga dipisahkan berdasarkan suatu kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.catplot(x=\"Parking\", y=\"House_Price\", hue=\"City_Category\", kind=\"box\", data=price2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada dugaan/interpretasi (baru) apakah dari boxPlot diatas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price2.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HeatMap untuk menyelidiki korelasi\n",
    "corr2 = price2.corr() # We already examined SalePrice correlations\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "sns.heatmap(corr2[(corr2 >= 0.5) | (corr2 <= -0.4)], \n",
    "            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.1,\n",
    "            annot=True, annot_kws={\"size\": 8}, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan Studi Kasus: Data Tips Restaurant\n",
    "\n",
    "Sebuah dataset dari suatu Restaurant memuat variabel-variabel berikut:\n",
    "*\ttotal_bill: Total bill (cost of the meal), including tax, in US dollars\n",
    "*\ttip: Tip (gratuity) in US dollars\n",
    "*\tsex: Sex of person paying for the meal (0=male, 1=female)\n",
    "*\tsmoker: Smoker in party? (0=No, 1=Yes)\n",
    "*\tday: 3=Thur, 4=Fri, 5=Sat, 6=Sun\n",
    "*\ttime: 0=Day, 1=Night\n",
    "*\tsize: Size of the party\n",
    "\n",
    "https://www.kaggle.com/ranjeetjain3/seaborn-tips-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Contoh Data studi kasus pertama di atas\n",
    "tips = sns.load_dataset('tips') # Loading dari SeaBorn library's dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tipe Datanya : DataFrame (df)\n",
    "type(tips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ukuran Data\n",
    "N, P = tips.shape\n",
    "print('baris = ', N, ', Kolom = ', P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Mengintip\" beberapa data pertamanya\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latihan:\n",
    "\n",
    "## Silahkan berdiskusi (sekaligus membagi task: latihan TeamWork) untuk menjawab pertanyaan-pertanyaan berikut:\n",
    "\n",
    "1. Adakah tipe variabel yang kurang tepat di data tersebut?\n",
    "2. Apakah data numeriknya cenderung berdistribusi normal?\n",
    "3. Apakah ada outlier, noise, missing values, dan-atau duplikasi data?\n",
    "4. Apakah pelanggan pria dan wanita cenderung proporsional (balance)?\n",
    "5. Dari data yang ada apakah Pria atau wanita ada kecenderungan memberi tips lebih besar?\n",
    "6. Dari data yang ada apakah ada kecenderungan tips lebih besar di hari-hari tertentu?\n",
    "7. Dari data yang ada apakah customer perokok cenderung memberi tips lebih besar?\n",
    "8. Apakah pola di nomer 5 dan 7 dipengaruhi hari?\n",
    "9. Pola apalagi yang dapat anda temukan? (misal, bisakah anda menyarankan tata letak kursi/meja restaurant dari data ini?)\n",
    "9. Final question: dari hasil EDA anda saran apa saja yang akan anda berikan ke pemilik restaurant? \n",
    "\n",
    "\n",
    "\n",
    "* **Jawaban ada di bagian bawah modul ini, tapi usahakan menjawab tanpa melihat jawabannya**\n",
    "* Skills/kompetensi apa yang terasa sangat diperlukan dari latihan ini?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jawaban Latihan Studi Kasus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ini adalah parameter tambahan jika kita juga ingin mendapatkan statistik sederhana seluruh datanya\n",
    "# (termasuk data kategorik)\n",
    "tips.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plots; https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "p = sns.pairplot(tips, hue=\"sex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plots; https://seaborn.pydata.org/generated/seaborn.pairplot.html\n",
    "p = sns.pairplot(tips, hue=\"day\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memilih hanya variable dengan tipe tertentu\n",
    "tips_num = tips.select_dtypes(include = ['float64', 'int64'])\n",
    "tips_num.head()\n",
    "# Perhatikan tis_num adalah variable df baru! ... (hati-hati di data yang besar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memilih hanya variable dengan tipe tertentu\n",
    "tips_cat = tips.select_dtypes(include = ['category'])\n",
    "tips_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribusi nilai pada setiap variabel kategorik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all unique values of a variable/column\n",
    "for col in tips_cat.columns:\n",
    "    print(col,': ', set(tips[col].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tips\n",
    "# Jika yang dibutuhkan memang hanya nama kolom, maka kita bisa melakukan hal ini untuk menghemat penggunaan memory\n",
    "numVar = tips.select_dtypes(include = ['float64', 'int64']).columns\n",
    "list(numVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribusi tiap data\n",
    "tips.smoker.value_counts()\n",
    "# kita bisa juga visualisasikan informasi ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PieChart\n",
    "plot = tips.sex.value_counts().plot(kind='pie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apakah ada kecenderungan hari dimana pengeluaran customer lebih besar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= sns.catplot(x=\"day\", y=\"total_bill\", data=tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jika dilihat hari dan gender?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= sns.catplot(x=\"day\", y=\"size\", hue=\"sex\", kind=\"swarm\", data=tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yang merokok cenderung memberi tips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = sns.catplot(x=\"smoker\", y=\"tip\", order=[\"No\", \"Yes\"], hue='day', data=tips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendahuluan Model Regresi\n",
    "\n",
    "* Digunakan saat variabel tak bebas (**Dependent variable** - Y) bertipe **numerik** (float/real) dan variabel bebasnya bisa numerik dan-atau kategorik\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Supervised_Methods.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/models_wrong_some_useful.png\" /></p>\n",
    "\n",
    "* Perfect/true-best model tidak ada, bahkan seringnya tidak diperlukan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beberapa contoh aplikasi regresi\n",
    "\n",
    "1. **Predictive** Analytics: Memprediksi resiko, harga, penjualan, demand, dsb.\n",
    "\n",
    "2. Operation Efficiency: Optimasi proses bisnis dengan melihat **hubungan antar variabel** dan mengambil policy berdasarkan hubungan tersebut.\n",
    "\n",
    "3. Supporting Decisions: **Testing hypothesis**, misal terkait keuangan, operations dan customer purchases.\n",
    "\n",
    "4. New **Insights**: Regresi dapat membantu menganalisa hubungan antar variabel dan sekaligus mem-filternya.\n",
    "\n",
    "Sumber: https://www.newgenapps.com/blog/business-applications-uses-regression-analysis-advantages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi dan Korelasi\n",
    "\n",
    "* Konsep dasar Persamaan/model Regressi adalah hubungan linear antara variabel bebas dan tak bebas.\n",
    "* Sehingga kita akan awali bahasannya dengan Korelasi\n",
    "\n",
    "<p><img alt=\"\" src=\"img/correlation.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Koefisien Korelasi Pearson\n",
    "\n",
    "* Korelasi adalah suatu pengukuran untuk melihat **hubungan linier** antara dua variable numerik. Disimbolkan dengan **r**, untuk sampel, dan **$\\rho$** untuk populasi.\n",
    "\n",
    "* Langkah pertama dalam penentuan korelasi adalah dengan membuat **diagram pencar** (scatter plot) dari variabel terkait. Pada korelasi, kedua variable setara, dalam artian tidak ada yang menjadi variable bebas dan terikat. \n",
    "\n",
    "* Namun, untuk mempermudah pembahasan, pada diagram pencar, satu variable akan disimbolkan sebagai *x* (variable bebas) dan satu variable sebagai *y* (variable terikat/tak bebas). Jika titik – titik data terkonsentrasi di sekitar garis lurus, maka merupakan indikasi bahwa korelasi antara kedua variable tinggi. Makin terpencar data dari suatu garis lurus, menunjukkan makin rendah korelasi antara kedua variable tersebut."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nilai koefisien korelasi Pearson\n",
    "\n",
    "* Nilai dari koefisien korelasi Pearson adalah dari -1 hingga +1.\n",
    "\n",
    "<p><img alt=\"\" src=\"img/korelasi_pearson_01.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/linear-nonlinear-relationships.png\" style=\"width: 688px; height: 266px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hati-hati\n",
    "\n",
    "* Koefisien korelasi = 0 bukan berarti tidak ada hubungan antara kedua variable. Yang benar adalah: tidak ada hubungan LINIER, tapi bisa jadi ada hubungan dalam bentuk lain; misal: kuadratik, atau fungsi lain selain linier, seperti pada contoh di atas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memahami Korelasi dari perumusannya (Statistical Thinking)\n",
    "\n",
    "* Korelasi sebenarnya adalah Covariance dibagi dengan masing-masing standar deviasinya.\n",
    "* Apa maksud/maknanya?\n",
    "\n",
    "<p><img alt=\"\" src=\"img/korelasi_pearson_formulae.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contoh sederhana\n",
    "\n",
    "<p><img alt=\"\" src=\"img/data_korelasi_01.png\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([40, 45, 53, 60, 65, 71]) # Usia\n",
    "y = np.array([126, 124, 135, 142, 139, 151]) # Tekanan Darah\n",
    "np.corrcoef(x, y)\n",
    "# Hasilnya adalah matriks korelasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretasi\n",
    "\n",
    "* Nilai ~0.95 menunjukkan bahwa ada korelasi linier positif yang kuat antara usia dan tekanan darah. Ada kecenderungan bahwa usia tinggi berkaitan dengan tekanan darah yang kebih tinggi dibandingkan usia rendah.\n",
    "* **WARNING**\n",
    "* **Korelasi tidak sama (meng-implikasikan) dengan sebab akibat**. Perhatikan interpretasi di atas. Tidak dinyatakan bahwa jika usia tinggi maka tekanan darah rendah, hanya suatu tren atau kecenderungan. Mungkin saja usia dengan bertambahnya usia maka tekanan darah meningkat, tapi mungkin juga tekanan darah tinggi bukan karena usia, tapi faktor lain yang tidak teramati pada data.\n",
    "\n",
    "* Contoh lain penelitian di Machine learning (kecantikan dan confidence/Panjang Jari dan IQ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batasan nilai $R^2$ seperti ini? ... Really? Why? Why not?\n",
    "\n",
    "<p><img alt=\"\" src=\"img/R_Squared_Interpretations.jpg\" /></p>\n",
    "\n",
    "* Cases (social, medicine, etc)\n",
    "* Objective, prediction vs insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi Linier Sederhana\n",
    "\n",
    "\n",
    "<img alt=\"\" src=\"img/Reg_sederhana_01.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/reg_eq.png\" style=\"width: 599px; height: 249px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/reg_types.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Korelasi ke Regresi\n",
    "\n",
    "<p><img alt=\"\" src=\"img/korelasi_2_regresi.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diskusi\n",
    "\n",
    "## Mengapa Error diasumsikan berdistribusi normal?\n",
    "## Error VS Residual?\n",
    "## Di dunia nyata kita seringnya tidak mengetahui error. Loh kok? Maksudnya?\n",
    "## Apa beda regresi dan interpolasi di Metode Numerik?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bahas sebentar pentingnya memahami \"Loss Function\"\n",
    "\n",
    "* Persamaan/Model Linier adalah dasar terpenting di Statistika, Data Science, Machine Learning, dan Deep Learning (*).\n",
    "* Banyak model di (*) sebenarnya adalah fungsi linier, bahkan di masalah klasifikasi.\n",
    "* Yang membedakan adalah \"pemodelan/optimasi masalah/Loss Functionnya\"\n",
    "\n",
    "-- Keterangan lebih lanjut ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heteroskedasticity\n",
    "\n",
    "<p><img alt=\"\" src=\"img/heterokedastisitas.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi memprediksi rata-rata $y_i$ untuk $x_i$, maksudnya?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Asumsi-Klasik\">Asumsi Klasik</h1>\n",
    "\n",
    "* http://taufiksutanto.blogspot.com/2018/05/asumsi-statistik-antara-benci-butuh.html\n",
    "<p><img alt=\"\" src=\"img/asumsi_reg.png\" style=\"width: 800px; height: 298px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/asumsi_reg_2.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some warnings in Regression\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Warnings_on_Regresi.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multikolinearitas: Mengapa dan seberapa \"robust\"?\n",
    "\n",
    "## Kapan kita tidak perlu hawatir tentang hal ini?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembahasan tentang Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pembahasan tentang Interpolasi dan bukan Ekstrapolasi \n",
    "\n",
    "## Kalau mau ekstrapolasi bagaimana?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagaimana jika error tidak berdistribusi \"normal\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://tau-data.id/asumsi-statistika-benci-butuh/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi Error (Mean Squared Error)\n",
    "\n",
    "<p><img alt=\"\" src=\"img/mse_regresi.png\" /></p>\n",
    "\n",
    "* Hati-hati,... perhatikan rumusnya dengan baik .... ia tidak robust terhadap outlier\n",
    "* $\\hat{y} = \\beta_0 + \\beta_1 x_1 + ... + \\beta_n x_n$\n",
    "* MSE = total jarak/selisih antara prediksi dan nilai dari data (sesungguhnya)\n",
    "* RMSE = $\\sqrt{MSE}$   ... why? \n",
    "* Evaluasi penting ketika kita ingin melakukan prediksi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi $R^2$: Model VS Tidak Pakai Model?\n",
    "\n",
    "<p><img alt=\"\" src=\"img/R_Square.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusted R-Squared? Why?\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Adjusted_R_Squared.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengaruh Variabel Tak Bebas ke Model\n",
    "\n",
    "\n",
    "<p><img alt=\"\" src=\"img/sig_var_di_Regresi.png\" /></p>\n",
    "\n",
    "* $SSR = SST - SSE = \\sum{(y_i-\\bar{y})^2} - \\sum{(y_i-\\hat{y_i})^2}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p-value (bergantung distribusi; contoh kasus distribusi normal)?\n",
    "\n",
    "<p><img alt=\"\" src=\"img/p-value.png\" /></p>\n",
    "\n",
    "* Probabilitas membuat kesalahan\n",
    "* Dari rumus di cell sebelumnya, ada \"masalah\" dengan formulasi p-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Menangani Data Kategorik di Regresi\n",
    "\n",
    "1. Numeric Encoding\n",
    "2. Dummy variable encoding\n",
    "3. One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh Data\n",
    "dt = [['female', 'New York', 'low', 4], ['female', 'London', 'medium', 3], ['male', 'New Delhi', 'high', 2]]\n",
    "col = ['Gender', 'City', 'Temperature', 'Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(dt,columns=col)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numeric encoding\n",
    "\n",
    "* Lebih cocok untuk ordinal (terutama jika kategorinya cukup banyak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['City_encoded'] = LabelEncoder().fit_transform(data['City'])\n",
    "data.head()\n",
    "# Hati-hati tidak ada urutan encodingnya, cocok untuk variabel nominal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customized Ordinal Numeric Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {'low':0, 'medium':1, 'high':2}\n",
    "data['Temperature_encoded'] = data['Temperature'].map(mapping)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding\n",
    "\n",
    "* Preferable in Machine learning community\n",
    "* Variabel nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Oh = pd.get_dummies(data['City'], prefix='City')\n",
    "Oh\n",
    "# Perhatikan, sekarang setiap kategori di variabel kategorik menjadi sebuah variabel baru\n",
    "# tapi bagaimana memasukan hasil encoding ini kembali ke datanya?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.concat([data, Oh], axis=1)\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dummy Variable (Statisticians)\n",
    "\n",
    "* less parameter\n",
    "* konsepnya seperti \"binary system\"\n",
    "* Statistician tidak suka jika jumlah parameter berlebih\n",
    "* default encoding beberapa modul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dum = pd.get_dummies(data['City'], prefix='City', drop_first=True)\n",
    "dum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([data, dum], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi Non-Linier?\n",
    "\n",
    "## Why?\n",
    "## Kapan tidak disarankan menambah kompleksitas model?\n",
    "## Regression for insights VS regression for prediction.\n",
    "\n",
    "## Masih linear terhadap parameter\n",
    "\n",
    "<p><img alt=\"\" src=\"img/linearisasi_regresi.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pentingnya \"scaling\" di Regresi (atau clustering) untuk mencari insight dari data\n",
    "\n",
    "<p><img alt=\"\" src=\"img/scaling.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/standardize.png\" /></p>\n",
    "<p><img alt=\"\" src=\"img/minmax.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floating Point tidak sama dengan Bilangan Real\n",
    "\n",
    "## Komputer tidak bisa menyimpan dan mengolah bilangan real\n",
    "# Tidak Percaya?\n",
    "## Mari hitung deret berikut dengan komputer (Python)\n",
    "# $\\sum_{n=1}^{10^6}0.1$\n",
    "## Seharusnya hasilnya adalah?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is the result according to Python\n",
    "dSum = 0 \n",
    "for i in range(10**6): # ini artinya for i dari 0 sampai (10^6)-1\n",
    "    dSum = dSum + 0.1 # or \"dSum += 0.1\"\n",
    "print(dSum)\n",
    "# is the result correct? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sistem Floating Point\n",
    "\n",
    "<p><img alt=\"\" src=\"img/6_float_3.png\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh\n",
    "# Load DataFile CSV\n",
    "try:\n",
    "    df = pd.read_csv('data/iklan.csv') # run locally\n",
    "except:\n",
    "    !wget https://raw.githubusercontent.com/taufikedys/ScienCom/master/data/iklan.csv # \"Google Colab\"\n",
    "    df = pd.read_csv('iklan.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standardize = preprocessing.StandardScaler()\n",
    "minMax = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = standardize.fit_transform(df[['Iklan', 'Laba']]) # Harus numerik dan Tidak Boleh ada Null/missing values\n",
    "st # hasilnya Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jika ingin dimasukkan lagi ke Dataframe awal\n",
    "st_df = pd.DataFrame(st, columns=['Iklan', 'Laba']) # Merubah Numpy Array menjadi DataFrame\n",
    "df2 = pd.concat([df, st_df], axis=1) # caranya sama dengan saat kita mendiskusikan encoding variabel kategorik\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similary untuk minMax\n",
    "mm = minMax.fit_transform(df[['Iklan', 'Laba']])\n",
    "mm_df = pd.DataFrame(mm, columns=['iklan_mm', 'laba_mm']) # Merubah Numpy Array menjadi DataFrame\n",
    "df3 = pd.concat([df, mm_df], axis=1) # caranya sama dengan saat kita mendiskusikan encoding variabel kategorik\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contoh Regresi di Python (Data Pengeluaran Biaya Iklan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un-command line below and run it \"Only If\" there is an error saying \"factorial not known\"\n",
    "#!pip install statsmodels==0.10.0rc2 --pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"No\", axis=1, inplace=True)\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sns.pairplot(df, hue=\"Tipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting model Regresi Sederhana\n",
    "lm = smf.ols(\"Laba ~ Iklan\", data=df[['Laba','Iklan']]).fit()\n",
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Squared Error\n",
    "lm.mse_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perintah-perintah ini hanya untuk memplot hasilnya\n",
    "xmin, xmax = df.Iklan.min(), df.Iklan.max()\n",
    "X = np.linspace(xmin, xmax, 100)\n",
    "# params[0] is the intercept (beta0)\n",
    "# params[1] is the slope (beta1)\n",
    "Y = lm.params[0] + lm.params[1] * X\n",
    "# Perhatikan ada 2 perintah plot\n",
    "plt.plot(df.Iklan, df.Laba, \"o\")\n",
    "plt.plot(X, Y, color=\"darkgreen\")\n",
    "#Selanjutnya hanya perintah labelling\n",
    "plt.xlabel(\"Investasi Iklan\")\n",
    "plt.ylabel(\"Laba\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan Module \"SeaBorn\" jauh lebih mudah ketimbang MatplotLib\n",
    "p = sns.regplot(df.Iklan, df.Laba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kita bisa prediksi dengan cara seperti ini:\n",
    "lm.predict({'Iklan': [21, 23, 25]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kenormalan residuals\n",
    "res = lm.resid # residuals\n",
    "fig = sm.qqplot(res, stats.t, fit=True, line='45')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresi Berganda dengan menambahkan variabel kategorik \"Tipe\"\n",
    "res = ols(formula='Laba ~ Iklan + C(Tipe)', data=df).fit()\n",
    "res.summary()\n",
    "# Perhatikan bentuk modelnya, terutama pada data kategorik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresi Berganda non-linear (mencoba transformasi logaritmik)\n",
    "res = ols(formula='Laba ~ np.log(Iklan) + C(Tipe)', data=df).fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train-Test untuk menghindari Overfit\n",
    "\n",
    "* Konsepnya generalisasi/\"inferensi\" Sample ==> Populasi, logical thinkingnya di aplikasi dunia nyata kita tidak memiliki nilai \"y\" (variabel target) yang sesungguhnya.\n",
    "* Catatan: pemisahan train-test menjaga proporsi kategori pada masalah klasifikasi (tidak murni random atau split)\n",
    "\n",
    "<p><img alt=\"\" src=\"img/train_test.png\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[['Iklan', 'Tipe']], df['Laba'], test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Belum Dibahas:\n",
    "\n",
    "* Model Regresi lain: Regression-tree, Support Vector Regression, Neural Network for Regression, dll.\n",
    "* Regresi untuk data khusus, misal Ridge Regression jika jumlah variabel banyak\n",
    "* General Linear Model dengan interaksi yang lebih umum/kompleks, dsb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/56_Supervised VS unsupervised.png\" style=\"height:500px; width:1153px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/5_Clus-Clas.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pendahuluan Klasifikasi \n",
    "\n",
    "<p><img alt=\"\" src=\"img/masalah_klasifikasi.png\" /></p>\n",
    "\n",
    "* Misal diberikan permasalahan terdapat dua buah kategori orange dan ungu seperti di gambar.\n",
    "* Setiap titik di ganmbar adalah entitas dari data yang terdiri dari beberapa variabel.\n",
    "* Jika diberikan titik baru (warna putih), maka masalah klasifikkasi adalah kemudian menggolongkan data baru ini ke kategori titik Orange atau Ungu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klasifikasi dengan Model Regresi Logistik\n",
    "\n",
    "<p><img alt=\"\" src=\"img/klas_regLogistik.png\" /></p>\n",
    "\n",
    "* Mencari garis lurus yang sedemikian sehingga kesalahan prediksinya sekecil mungkin (lihat gambar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi Logistik\n",
    "\n",
    "* Awalnya regresi logistik adalah metode klasifikasi binary: membedakan antara 2 kelas atau kategori.\n",
    "* Masalah klasifikasi binary contohnya memprediksi seseorang terkena \"kanker\" atau \"tidak kanker\", kanker jinak/ganas, fraud atau bukan fraud (pada transaksi keuangan), negatif/positif dalam sentimen analisis, dsb.\n",
    "* Regresi logistik adalah pengembangan dari model regresi liniear, namun di konversi ke masalah klasifikasi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi Logistik\n",
    "\n",
    "<img alt=\"\" src=\"img/reg_to_log.png\" />\n",
    "\n",
    "* http://www.saedsayad.com/logistic_regression.htm\n",
    "* Makna fungsi logarithm?\n",
    "* Konsekuensi dari rumus $\\beta$ diatas?\n",
    "* Asumsi?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaitan Regresi Logistik dan Neural Network/Deep Learning\n",
    "\n",
    "<img alt=\"\" src=\"img/logReg_NN_DL.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"img/Fungsi_Sigmoid.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Linear Regression\n",
    "\n",
    "<p><img alt=\"\" src=\"img/LogReg_When2use.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Over Fitting?\n",
    "\n",
    "\n",
    "<p><img alt=\"\" src=\"img/under-over_Fitting.jpg\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/sweet_spot.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Regularization\">Regularization</h2>\n",
    "\n",
    "* Misal $\\beta$ ==> $w$\n",
    "* Di perumusan regresi logistik awal, ada kemungkinan beta akan selalu positif dan besar (walau mungkin variabelnya kurang/tidak signifikan menerangkan variabel target ~ y).\n",
    "* Untuk mencegah hal ini (~over fitting), model supervised learning (klasifikasi) menggunakan teknik regulerisasi.\n",
    "* Konsep Regularisasi tidak hanya digunakan dalam regresi logistik, namun juga model lain seperti SVM, JST, Deep Learning, dll.\n",
    "* Memahami konsep ini akan sangat bermanfaat di Data Science.\n",
    "* Misal E(w) adalah fungsi error/loss function yang sudah kita sebelumnya dan $t_n$ adalah nilai sesungguhnya, maka regulerisasi dilakukan dengan mengoptimalkan fungsi berikut ini:\n",
    "\n",
    "<p><img alt=\"\" src=\"img/L2_regularization_LogReg.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diskusi\n",
    "\n",
    "* Regresi Logistik tidak dapat mengolah data yang mengandung \"missing values\"/null, mengapa?\n",
    "* Jika kita merubah persamaannya (misal dengan mencoba berbagai transformasi variabel) sedemikian sehingga didapatkan model yang sedikit lebih baik (akurasinya) dibandingkan model yang lebih sederhana, apakah kita akan menggunakan model tersebut? Mengapa?\n",
    "* Seperti regresi linear, apakah kita perlu standarisasi/scaling data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contoh Aplikasi\n",
    "\n",
    "* Data klasifikasi bunga Iris sebagai studi kasus sederhana\n",
    "* Link data: https://archive.ics.uci.edu/ml/datasets/iris\n",
    "* Paper sumber data: Fisher,R.A. \"The use of multiple measurements in taxonomic problems\" Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to Mathematical Statistics\" (John Wiley, NY, 1950). \n",
    "* Masalah klasifikasinya adalah mengklasifikasikan jenis Bunga Iris berdasarkan bentuk (e.g. panjang dan lebar) bunga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df = pd.read_excel('data/iris.xls', sheet_name='Sheet1')# Load \"sheet_1\" di Excell\n",
    "except:\n",
    "    !wget https://github.com/taufikedys/ScienCom/blob/master/data/iris.xls?raw=true # \"Google Colab\"\n",
    "    df = pd.read_excel('iris.xls', sheet_name='Sheet1')\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data ini bukan murni Binary Classification\n",
    "# Kita akan ambil sebagiannya untuk menjadikannya masalah binary classification\n",
    "set(df['SPECIES'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bentuk data binary dari sini menggunakan teknik di Modul 03: EDA\n",
    "# Disimpan dalam variabel baru \"df_bin\"\n",
    "df_bin = df[df[\"SPECIES\"].isin([1,2]) ]\n",
    "set(df_bin['SPECIES'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bin.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pisahkan menjadi training dan Test Data seperti Module sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_bin[['SEPALLEN', 'SEPALWID','PETALLEN','PETALWID']], df_bin['SPECIES'], test_size=0.5, random_state=99)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pemodelan Regresi Logistik menggunakan Python (module SciKit-Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediksi ke data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_reglog = clf.predict(X_test)\n",
    "y_reglog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seberapa \"baik\" prediksi ini? = Akurasi/Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pertama-tama Kita gunakan metric/pengukuran yang umum\n",
    "accuracy_score(y_test, y_reglog)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contoh data lain: Data Klasifikasi Kanker\n",
    "\n",
    "* Dapat diunduh dari link ini: https://goo.gl/U2Uwz2\n",
    "* Link scikit utk datanya: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html#sklearn.datasets.load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()\n",
    "prnt(type(data))\n",
    "X = data.data\n",
    "print(type(X), X.shape)\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "print(type(X), X.shape)\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.target\n",
    "print(type(Y), Y.shape)\n",
    "print(data.target_names)\n",
    "Y[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.5, random_state=99)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression().fit(X_train, y_train)\n",
    "y_reglog = clf.predict(X_test)\n",
    "accuracy_score(y_test, y_reglog)\n",
    "# Masih \"mudah\", namun lebih baik dari sebelumnya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persamaannya? (ada 30 variabel)\n",
    "clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric Evaluasi yang lain\n",
    "\n",
    "<p><img alt=\"\" src=\"img/6_Evaluasi_ML.JPG\" /></p>\n",
    "\n",
    "## http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Confusion-Matrix\">Confusion Matrix</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/confusion_matrix.png\" /></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>sensitivity, recall, hit rate, or true positive rate (TPR)</li>\n",
    "\t<li>precision or positive predictive value (PPV)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/FP-FN_Meme.jpg\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/ex-F1-Score.png\" /></p>\n",
    "* Yang mana kategori yang \"positif\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/F-beta-Score.png\" /></p>\n",
    "\n",
    "* $0\\leq F\\leq 1$, 1 optimal value\n",
    "* $0\\leq\\beta< \\inf$\n",
    "* beta < 1 lends more weight to precision, \n",
    "* beta > 1 favors recall \n",
    "* beta -> 0 considers only precision \n",
    "* beta -> inf only recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplikasi di Python untuk metrics diatas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('presisi = ', precision_score(y_test, y_reglog))\n",
    "print('Recall = ', recall_score(y_test, y_reglog))\n",
    "print('f1_score = ', f1_score(y_test, y_reglog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atau ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_reglog))\n",
    "print(classification_report(y_test, y_reglog))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluasi yang kita lakukan belum cukup valid/objektif ... Mengapa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Cross Validation</h1>\n",
    "\n",
    "<img alt=\"\" src=\"img/6_Cross_validation.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n",
    "# Perhatikan variabelnya, kita sekarang menggunakan seluruh data\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n",
    "mulai = time.time()\n",
    "scores_regLog = cross_val_score(clf, X, Y, cv=10) # perhatikan sekarang kita menggunakan seluruh data\n",
    "waktu = time.time() - mulai\n",
    "# Interval Akurasi 95 CI \n",
    "print(\"Accuracy Regresi Logistik: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_regLog.mean(), scores_regLog.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kita juga bisa menampilkan BoxPlotnya untuk mendapatkan informasi yang lebih lengkap\n",
    "df = pd.DataFrame({'Regresi Logistik':scores_regLog})\n",
    "sns.boxplot(data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresi Logistik untuk Multiclass Classification?\n",
    "\n",
    "## Salah satu caranya: One Versus All (OVA) Approach\n",
    "\n",
    "<p><img alt=\"\" src=\"img/ova.png\" /></p>\n",
    "\n",
    "## Aplikasi di Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_iris(return_X_y=True)\n",
    "set(y) # 3 Kategori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape # 4 variabel, 150 baris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(multi_class='ovr').fit(X, y)\n",
    "clf.coef_\n",
    "# Perhatikan ada 3 persamaan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbour\n",
    "\n",
    "\n",
    "<img alt=\"\" src=\"img/kNN_plot.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>k-Nearest Neighbour</h3>\n",
    "<ul>\n",
    "\t<li>Classifier yang paling sederhana, namun dapat juga digunakan untuk regresi (dan bahkan clustering).</li>\n",
    "\t<li>Sering disebut sebagai <u><strong>Instance based Learner</strong></u></li>\n",
    "    <li>Tidak memiliki \"persamaan\", pendekatannya lebih ke algoritmik berdasarkan konsep jarak/similarity</li>\n",
    "    <li>Mirip konsep DBSCAN</li>\n",
    "</ul>\n",
    "<img alt=\"\" src=\"img/6_kNN.JPG\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"k-NN-Neighbour-Size\">k-NN Neighbour Size</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/k-NN_neighbour_size.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<dl>\n",
    "\t<dt><strong>Pros:</strong></dt>\n",
    "\t<dd>\n",
    "\t<ul>\n",
    "\t\t<li>Relatif cepat (efisien) untuk data yang tidak terlalu besar</li>\n",
    "\t\t<li>Sederhana, mudah untuk diimplementasikan</li>\n",
    "\t\t<li>Mudah untuk di modifikasi: Berbagai macam formula jarak/similaritas</li>\n",
    "\t\t<li>Menangani data Multiclass dengan mudah</li>\n",
    "\t\t<li>Akurasi cukup baik jika data representatif</li>\n",
    "\t</ul>\n",
    "\t</dd>\n",
    "\t<dt><strong>Cons:</strong></dt>\n",
    "\t<dd>\n",
    "\t<ul>\n",
    "\t\t<li>Menemukan&nbsp;nearest neighbours tidak efisien untuk data besar</li>\n",
    "\t\t<li>Storage of data</li>\n",
    "\t\t<li>Meyakinkan rumus jarak yang tepat</li>\n",
    "\t</ul>\n",
    "\t</dd>\n",
    "</dl>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity (Distance)\n",
    "* Euclidean (“straight line”, distance between two points)\n",
    "* Manhattan (sum of absolute differences of all attributes)\n",
    "* Maximal (greatest of absolute differences between attributes) <br>\n",
    "  d(x,y) = max{|x_i-y_i|, i =1,2,...,n}\n",
    "* Mahalanobis (distance between point and distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Euclidean-Distance\">Euclidean Distance</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Euclidean.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Manhattan-Distance\">Manhattan Distance</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/manhattan.png\" style=\"width: 450px; height: 146px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity explained in plain terms and its application in Python\n",
    "### http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/other_Distance.gif\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"The-Weights-in-Orange's-k-NN:\">The Weights in  k-NN:</h2>\n",
    "\n",
    "<ul>\n",
    "\t<li><big><strong>Uniform</strong></big>: all points in each neighborhood are weighted equally.</li>\n",
    "\t<li><big><strong>Distance</strong></big>: closer neighbors of a query point have a greater influence than the neighbors further away.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplikasi di Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-NN: http://scikit-learn.org/stable/modules/neighbors.html\n",
    "from sklearn import neighbors\n",
    "\n",
    "n_neighbors = 9\n",
    "weights = 'distance'\n",
    "kNN = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "kNN.fit(X_train, y_train)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediksi dengan k-NN\n",
    "y_kNN = kNN.predict(X_test)\n",
    "y_kNN[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Akurasi\n",
    "accuracy_score(y_test, y_kNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validasi\n",
    "del kNN\n",
    "kNN = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "\n",
    "mulai = time.time()\n",
    "scores_kNN = cross_val_score(kNN, X, y, cv=10) # perhatikan sekarang kita menggunakan seluruh data\n",
    "waktu = time.time() - mulai\n",
    "# Interval Akurasi 95 CI \n",
    "print(\"Accuracy kNN: %0.2f (+/- %0.2f), Waktu = %0.3f detik\" % (scores_kNN.mean(), scores_kNN.std() * 2, waktu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree (Pohon Keputusan)\n",
    "\n",
    "<img alt=\"\" src=\"img/tree_plot.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"img/6_DT.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"img/6_DT_meme.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pengaruh \"ketinggian\" tree terhadap bentuk model\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Dec_Tree_Asumsi_Depth.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teori Decision Tree : Information theory\n",
    "<img alt=\"\" src=\"img/dec_Tree_Theory.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/Entropy.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/Information_Gain.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/Contoh_Entropy.png\" style=\"width: 469px; height: 339px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/Contoh_Gain.png\" style=\"width: 650px; height: 456px;\" /></p>\n",
    "\n",
    "* Contoh Lain: http://www.saedsayad.com/decision_tree.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternative to Information Gain : Gini Index (CART)\n",
    "https://medium.com/deep-math-machine-learning-ai/chapter-4-decision-trees-algorithms-b93975f7a1f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><u><strong>When to use:</strong></u></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Target : Binomial/nominal.</li>\n",
    "\t<li>Predictors (input): binomial, nominal, and-or interval (ratio).</li>\n",
    "</ul>\n",
    "\n",
    "<p><u><strong>Advantage:</strong></u></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Fast and embarrassingly parallel.</li>\n",
    "\t<li>Tanpa iterasi, cocok untuk&nbsp;Big Data technology (e.g. Hadoop)[map-reduce friendly]</li>\n",
    "\t<li>Interpretability</li>\n",
    "\t<li>Robust terhadap outliers &amp; missing values</li>\n",
    "</ul>\n",
    "\n",
    "<p><u><strong>Disadvantage:</strong></u></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Non probabilistic (ad hoc heuristic) +/-</li>\n",
    "\t<li>Target dengan banyak kelas</li>\n",
    "\t<li>Sensitive (instability)</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree: http://scikit-learn.org/stable/modules/tree.html\n",
    "from sklearn import tree\n",
    "\n",
    "DT = tree.DecisionTreeClassifier()\n",
    "DT = DT.fit(X_train, y_train)\n",
    "y_DT = DT.predict(X_test)\n",
    "print(accuracy_score(y_test, y_DT))\n",
    "print(confusion_matrix(y_test, y_DT))\n",
    "print(classification_report(y_test, y_DT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ulang Data\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel('data/iris.xls', sheet_name='Sheet1')# Load \"sheet_1\" di Excell\n",
    "except:\n",
    "    !wget https://github.com/taufikedys/ScienCom/blob/master/data/iris.xls?raw=true # \"Google Colab\"\n",
    "    df = pd.read_excel('iris.xls', sheet_name='Sheet1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Data\n",
    "X = df[['SEPALLEN','SEPALWID','PETALLEN','PETALWID']]\n",
    "Y = df['SPECIES']\n",
    "seed = 9\n",
    "validation_size = 0.3\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=validation_size, random_state=seed)\n",
    "print(X_train.shape, len(Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model and Evaluate\n",
    "dt_model = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=seed) # Default Gini\n",
    "dt = dt_model.fit(X_train, Y_train)\n",
    "dt_prediction = dt.predict(X_test)\n",
    "print('Akurasi = ', accuracy_score(Y_test, dt_prediction))\n",
    "print(confusion_matrix(Y_test, dt_prediction))\n",
    "print(classification_report(Y_test, dt_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varible importance - Salah satu kelebihan Decision Tree\n",
    "dt.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt-get install graphviz\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(viz.svg()))\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = tree.export_graphviz(dt, out_file=None) \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"iris\") \n",
    "var_names = ['SEPALLEN','SEPALWID', 'PETALLEN','PETALWID']\n",
    "categories = ['Setosa', 'VersiColor', 'Virginica']\n",
    "dot_data = tree.export_graphviz(dt, out_file=None, \n",
    "                         feature_names = var_names,  \n",
    "                         class_names=categories,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "<img alt=\"\" src=\"img/naive_bayes.png\" />\n",
    "\n",
    "<ul>\n",
    "\t<li>P(x) konstan, sehingga bisa diabaikan.</li>\n",
    "\t<li>Asumsi terkuatnya adalah independensi antar variabel prediktor (sehingga dikatakan &quot;Naive&quot;)</li>\n",
    "\t<li>Klasifikasi dilakukan dengan menghitung probabilitas untuk setiap kategori ketika diberikan data x = (x1,x2,...,xm)</li>\n",
    "\t<li>Untuk data yang besar bisa menggunakan out-of-core approach (partial fit):<br />\n",
    "\thttp://scikit-learn.org/stable/modules/scaling_strategies.html#scaling-strategies</li>\n",
    "\t<li>Variasi NBC adalah bagaimana P(c|x) dihitung, misal dengan distribusi Gaussian (Normal) - sering disebut sebagai Gaussian Naive Bayes (GNB):</li>\n",
    "</ul>\n",
    "\n",
    "<img alt=\"\" src=\"img/Gaussian.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><em><strong>Pros:</strong></em></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Cepat dan mudah di implementasikan</li>\n",
    "\t<li>Cocok untuk permasalahan multiclass</li>\n",
    "\t<li>Jika asumsi terpenuhi (independent) biasanya performanya cukup baik dan membutuhkan data (training) yang lebih sedikit.</li>\n",
    "\t<li>Biasanya baik digunakan untuk prediktor kategorik, untuk numerik NBC mengasumsikan distribusi normal (terkadang tidak terpenuhi)&nbsp;</li>\n",
    "</ul>\n",
    "\n",
    "<p><em><strong>Cons:</strong></em></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Jika di test data memuat kategori yang tidak ada di training data ( ==&gt; probabilitas = 0). Sering disebut sebagai masalah&nbsp; &ldquo;Zero Frequency&rdquo;.&nbsp;</li>\n",
    "\t<li>Asumsi yang sangat kuat (independen antar prediktor).</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplikasi di Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes: http://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "nbc = gnb.fit(X_train, Y_train)\n",
    "nbc_prediction = nbc.predict(X_test)\n",
    "\n",
    "print('Akurasi = ', accuracy_score(Y_test, nbc_prediction))\n",
    "print(confusion_matrix(Y_test, nbc_prediction))\n",
    "print(classification_report(Y_test, nbc_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membandingkan model-model yang sudah kita bahas sejauh ini\n",
    "\n",
    "* Code-nya bisa dimodifikasi sedikit untuk perbandingan model yang lain atau data yang lain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Comparisons using Cross Validation\n",
    "X = df[['SEPALLEN','SEPALWID','PETALLEN','PETALWID']]\n",
    "Y = df['SPECIES']\n",
    "\n",
    "Models = [('Regresi Logistik',clf), ('k-NN',kNN),('Naive Bayes',gnb), ('Decision Tree',DT)]\n",
    "Scores = {}\n",
    "for model_name, model in Models:\n",
    "    if model_name=='Naive Bayes':\n",
    "        Scores[model_name] = cross_val_score(model, X.values, Y, cv=10,scoring='accuracy')\n",
    "    else:\n",
    "        Scores[model_name] = cross_val_score(model, X, Y, cv=10,scoring='accuracy')\n",
    "        \n",
    "dt = pd.DataFrame.from_dict(Scores)\n",
    "ax = sns.boxplot(data=dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM)\n",
    "Misal data dinyatakan sebagai berikut:\n",
    "$\\{(\\bar{x}_1,y_1),...,(\\bar{x}_n,y_n)\\}$, dimana $\\bar{x}_i$ adalah\n",
    "input pattern untuk data ke $i^{th}$ dan $y_i$ adalah nilai target yang diinginkan. Kategori\n",
    "(class) direpresentasikan dengan $y_i=\\{-1,1\\}$. Sebuah bidang datar (hyperplane) yang memisahkan kedua kelas ini (\"linearly separable\") adalah:\n",
    "$$ \\bar{w}'\\bar{x}+b=0 $$\n",
    "dimana $\\bar{x}$ adalah input vector (prediktor), $\\bar{w}$ weight, dan $b$ disebut sebagai bias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pemodelan SVM (Hard Margin):\n",
    "\n",
    "<img alt=\"\" src=\"img/Pemodelan_SVM_.png\" style=\"width: 250px ; height: 269px\" />\n",
    "\n",
    "* Misal **Xo** adalah sebuah vector di bidang (plane/garis) _wX + b = -1_\n",
    "* Misal **r** adalah jarak antar SV-nya.\n",
    "* karena **X** berada di bidang _wX+b=1_ maka  _X=Xo+rw/||w||_ \n",
    "* (lihat gambar *w* tegak lurus *X* (karena _wX+b=0_) dan _w/||w||_ adalah unit vektornya)\n",
    "* Sehingga _wX+b=1_ dapat dituliskan sebagai _w(Xo+r w/||w||)-b = 1_\n",
    "* atau _wXo+r||w||²/||w||-b=1_ ==> _wXo-b=1-r||w||_ ==> _-1=1-r||w||_\n",
    "* sehingga di dapat $r = \\frac{2}{||w||}$\n",
    "* Kesimpulannya optimal hyperplane bisa didapatkan dengan memaksimumkan $\\frac{2}{||w||}$ atau setara dengan $\\min \\frac{||w||}{2}$\n",
    "* More details here: https://nlp.stanford.edu/IR-book/html/htmledition/support-vector-machines-the-linearly-separable-case-1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"img/hard_margin_svm.png\" style=\"width: 400px; height: 181px;\" />\n",
    "* Efek outlier pada pemodelan ini?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh plotting Optimal Hyperplane\n",
    "# http://scikit-learn.org/stable/auto_examples/svm/plot_separating_hyperplane.html#example-svm-plot-separating-hyperplane-py\n",
    "\n",
    "X, y = make_blobs(n_samples=20, centers=2, random_state=6) # we create 20 separable points\n",
    "clf = svm.SVC(kernel='linear', C=1000) # fit the model, don't regularize for illustration purposes\n",
    "clf.fit(X, y)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap=plt.cm.Paired)\n",
    "ax = plt.gca();xlim = ax.get_xlim(); ylim = ax.get_ylim()\n",
    "\n",
    "# create grid to evaluate model\n",
    "xx = np.linspace(xlim[0], xlim[1], 30);yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)\n",
    "ax.contour(XX, YY, Z, colors='k', levels=[-1, 0, 1], alpha=0.5,linestyles=['--', '-', '--'])# plot decision boundary and margins\n",
    "ax.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=100,linewidth=1, facecolors='none', edgecolors='k')# plot support vectors\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine: Soft Margin\n",
    "\n",
    "<img alt=\"\" src=\"img/6_SVM.jpg\" style=\"height: 262px ; width: 232px\" />\n",
    "<img alt=\"\" src=\"img/svm_opt.png\" style=\"width: 300px; height: 106px;\" />\n",
    "\n",
    "* Apakah efek outlier masih sama pada pemodelan ini? Kaitannya dengan nilai C?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C >>> ==> toleransi terhadap outlier <<<< dan sebaliknya"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dual dan Quadratic solver\n",
    "* optimasi di atas biasanya diselesaikan dengan mencari bentuk *Dual*-nya.\n",
    "* Solusi untuk parameter optimalnya kemudian ditemukan dengan mencari pendekatan nilai optimalnya lewat Quadratic Programming solver.\n",
    "* Perhatikan bahwa bentuk fungsi optimasinya konvex ==> memiliki minimum global.\n",
    "* Nilai optimal dari pemodelan di atas hanya bergantung pada data-data di margin (support vector) sehingga bisa lebih efisien (jika SV telah diketahui).\n",
    "* SV juga dapat digunakan untuk menganalisa \"Error Bound\" : http://www.svms.org/vc-dimension/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "* Recursive Feature Elimination (RFE) method : https://link.springer.com/content/pdf/10.1023/A:1012487302797.pdf \n",
    "* melihat bentuk kuadrat dari setiap komponen *w* (higher better).\n",
    "* hati-hati beberapa diskusi di internet menyatakan bahwa sign (+/-) menyatakan tingkat kepentingan terhadap setiap variabel, namun hal ini tidak selalu benar dan bisa dibuktikan cukup dengan counter example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SVM Kernel (trick)</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/6_SVM_Kernel.jpg\" style=\"height:168px; width:306px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Well-Known-Kernel-Functions\">Well-Known Kernel Functions</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Well-Known_Kernels.png\" style=\"width: 400px; height: 208px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>SVM Binary to MultiClass</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/6_SVM_Ova.jpg\" style=\"height:314px; width:432px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><b>Pros</b></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Akurasinya Baik</li>\n",
    "\t<li>Bekerja dengan baik untuk sampel data yang relatif kecil</li>\n",
    "\t<li>Hanya bergantung pada SV ==&gt; meningkatkan efisiensi</li>\n",
    "\t<li>Convex ==&gt; Minimum Global ==&gt; Pasti Konvergen</li>\n",
    "</ul>\n",
    "\n",
    "<p><b>Cons</b></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Tidak efisien untuk data yang besar</li>\n",
    "\t<li>Akurasi terkadang rendah untuk multiklasifikasi (sulit mendapatkan hubungan antar kategori di modelnya)</li>\n",
    "\t<li>Tidak robust terhadap noise</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the data\n",
    "X = df[['SEPALLEN','SEPALWID','PETALLEN','PETALWID']]\n",
    "Y = df['SPECIES']\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3)\n",
    "print(X_train.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting and evaluate the model\n",
    "dSVM = svm.SVC(C = 10**5, kernel = 'linear')\n",
    "dSVM.fit(X_train, Y_train)\n",
    "y_SVM = dSVM.predict(X_test)\n",
    "print('Akurasi = ', accuracy_score(Y_test, y_SVM))\n",
    "print(confusion_matrix(Y_test, y_SVM))\n",
    "print(classification_report(Y_test, y_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Support Vectors\n",
    "print('index dr SV-nya: ', dSVM.support_)\n",
    "print('Vector Datanya: \\n', dSVM.support_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Weights for interpretations\n",
    "print('w = ',dSVM.coef_)\n",
    "print('b = ',dSVM.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan Kernel: http://scikit-learn.org/stable/modules/svm.html#svm-kernels\n",
    "for kernel in ('sigmoid', 'poly', 'rbf'):\n",
    "    dSVM = svm.SVC(kernel=kernel)\n",
    "    dSVM.fit(X_train, Y_train)\n",
    "    y_SVM = dSVM.predict(X_test)\n",
    "    print(accuracy_score(Y_test, y_SVM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiklasifikasi SVM (contoh 3 kelas di data Iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh Multiklasifikasi SVM (dengan dan tanpa kernel)\n",
    "df = pd.read_excel('data/iris.xls', sheet_name='Sheet1')# Load Data from File\n",
    "df['SPECIES'] = df['SPECIES'].astype('category')\n",
    "X = df[['SEPALLEN','SEPALWID','PETALLEN','PETALWID']]\n",
    "Y = df['SPECIES']\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3)\n",
    "print(X_train.shape, X_test.shape)\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Versus All: http://www.jmlr.org/papers/volume5/rifkin04a/rifkin04a.pdf\n",
    "dSVM = svm.LinearSVC()\n",
    "dSVM.fit(X_train, Y_train)\n",
    "y_SVM = dSVM.predict(X_test)\n",
    "print('Akurasi = ', accuracy_score(Y_test, y_SVM))\n",
    "y_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ada 3 classifier (as expected)\n",
    "dSVM.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All At Once Method http://www.jmlr.org/papers/volume2/crammer01a/crammer01a.pdf\n",
    "dSVM = svm.SVC(decision_function_shape='ovo')\n",
    "dSVM.fit(X_train, Y_train)\n",
    "y_SVM = dSVM.predict(X_test)\n",
    "print('Akurasi = ', accuracy_score(Y_test, y_SVM))\n",
    "y_SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Artificial-Neural-Network---Jaringan-Syaraf-tiruan\">Artificial Neural Network - Jaringan Syaraf Tiruan</h1>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/JST.jpg\" style=\"width: 600px; height: 362px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN (JST)\n",
    "\n",
    "<p><img alt=\"\" src=\"img/ANN_plot.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"img/6_JST.JPG\" style=\"height:400px; width:706px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/6_JST_calculation.JPG\" style=\"height:350px; width:638px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"img/6_JST_Actv.png\" style=\"height:400px; width:484px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass ANN\n",
    "<img alt=\"\" src=\"img/Multiclass_ANN.png\" style=\"width: 600px; height: 468px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Melihat pemodelan Matematis dan cara kerja Neural Network, apakah kita perlu melakukan standarisasi data juga seperti SVM dan Regresi Logistic?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Neural Network - Empirical Analysis Parameter di ANN</p>\n",
    "<strong><a href=\"https://goo.gl/3rcnc9\" target=\"_blank\">https://goo.gl/3rcnc9</a></strong>\n",
    "\n",
    "\n",
    "<p>Mengapa dengan fungsi linear bisa membentuk &quot;boundary&quot; yang melengkung (kurva)?</p>\n",
    "<strong><a href=\"http://s.id/j6i\" target=\"_blank\">http://s.id/j6i</a></strong>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/6_tipe_NN.png\" style=\"height:400px; width:711px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network VS Deep Learning\n",
    "<img alt=\"\" src=\"img/5_DeepLearning.png\" style=\"width: 600px; height: 676px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/6_NN_when_to_use.JPG\" style=\"height:400px; width:499px\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network: http://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "NN = MLPClassifier(hidden_layer_sizes=(30,20, 10))# 2 layers 30 neurons and 20 neurons\n",
    "NN.fit(X_train, Y_train)\n",
    "y_NN = NN.predict(X_test)\n",
    "print('Akurasi = ', accuracy_score(Y_test, y_NN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Induktif bias :\n",
    "<ul>\n",
    "\t<li>Bias penaksiran parameter (statistik)</li>\n",
    "\t<li>Induktif Bias Sample (Machine Learning - Tom Mitchel)</li>\n",
    "\t<li>Induktif Bias Pemilihan Classifier (Statistical Learning Theory - Vapnik)</li>\n",
    "</ul>\n",
    "<img alt=\"\" src=\"img/inductive_biases_.png\" style=\"width: 600px; height: 153px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ilustrasi Induktif Bias Pemilihan Model dengan Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h, i = .02, 1  # step size in the mesh , iterate over datasets\n",
    "names = [\"Nearest Neighbors\", \"Logistic Regression\", \"Naive Bayes\", \"Linear SVM\", \"RBF SVM\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\"]\n",
    "\n",
    "classifiers = [KNeighborsClassifier(3),\n",
    "    LogisticRegression(solver='lbfgs',multi_class='multinomial'),\n",
    "    GaussianNB(), SVC(kernel=\"linear\", C=0.025), SVC(gamma=2, C=1),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1)]\n",
    "\n",
    "X, y = make_classification(n_features=2, n_redundant=0, n_informative=2,random_state=1, n_clusters_per_class=1)\n",
    "rng = np.random.RandomState(2)\n",
    "X += 2 * rng.uniform(size=X.shape)\n",
    "linearly_separable = (X, y)\n",
    "\n",
    "datasets = [make_moons(noise=0.3, random_state=0),make_circles(noise=0.2, factor=0.5, random_state=1),linearly_separable]\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "\n",
    "for ds_cnt, ds in enumerate(datasets):\n",
    "    # preprocess dataset, split into training and test part\n",
    "    X, y = ds\n",
    "    X = preprocessing.StandardScaler().fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=42)\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),np.arange(y_min, y_max, h))\n",
    "\n",
    "    # just plot the dataset first\n",
    "    cm = plt.cm.RdBu\n",
    "    cm_bright = ListedColormap(['#FF0000', '#0000FF'])\n",
    "    ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "    if ds_cnt == 0:\n",
    "        ax.set_title(\"Input data\")\n",
    "    # Plot the training points\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,\n",
    "               edgecolors='k')\n",
    "    # Plot the testing points\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6,\n",
    "               edgecolors='k')\n",
    "    ax.set_xlim(xx.min(), xx.max()); ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(()); ax.set_yticks(())\n",
    "    i += 1\n",
    "\n",
    "    # iterate over classifiers\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        ax = plt.subplot(len(datasets), len(classifiers) + 1, i)\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "\n",
    "        # Plot the decision boundary. For that, we will assign a color to each\n",
    "        # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "        if hasattr(clf, \"decision_function\"):\n",
    "            Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "        else:\n",
    "            Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "\n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        ax.contourf(xx, yy, Z, cmap=cm, alpha=.8)\n",
    "\n",
    "        # Plot the training points\n",
    "        ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright,edgecolors='k')\n",
    "        # Plot the testing points\n",
    "        ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright,edgecolors='k', alpha=0.6)\n",
    "\n",
    "        ax.set_xlim(xx.min(), xx.max());ax.set_ylim(yy.min(), yy.max())\n",
    "        ax.set_xticks(()); ax.set_yticks(())\n",
    "        if ds_cnt == 0:\n",
    "            ax.set_title(name)\n",
    "        ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'),\n",
    "                size=15, horizontalalignment='right')\n",
    "        i += 1\n",
    "\n",
    "plt.tight_layout();plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Ensemble-Model\">Ensemble Model</h2>\n",
    "\n",
    "<ul>\n",
    "\t<li>What? a learning algorithms that construct a set of classifiers and then classify new data points by taking a (weighted) vote of their predictions.</li>\n",
    "\t<li>Why? Better prediction, More stable model</li>\n",
    "\t<li>How? Bagging &amp; Boosting</li>\n",
    "</ul>\n",
    "<img alt=\"\" src=\"img/Ensemble.png\" style=\"width: 500px; height: 213px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## “meta-algorithms” : Bagging & Boosting\n",
    "* Ensemble https://www.youtube.com/watch?v=Un9zObFjBH0 \n",
    "* Bagging https://www.youtube.com/watch?v=2Mg8QD0F1dQ \n",
    "* Boosting https://www.youtube.com/watch?v=GM3CDQfQ4sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/Bagging_VS_Boosting.png\" style=\"width: 500px; height: 185px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img alt=\"\" src=\"img/Bagging-Boosting_Usage.png\" style=\"width: 500px; height: 281px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Ada-Boost\">AdaBoost</h2>\n",
    "<ul>\n",
    "\t<li><a href=\"https://youtu.be/BoGNyWW9-mE?t=70\" target=\"_blank\">https://youtu.be/BoGNyWW9-mE?t=70</a></li>\n",
    "</ul>\n",
    "<img alt=\"\" src=\"img/AdaBoost.png\" style=\"width: 400px; height: 332px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh Voting (Bagging) di Python\n",
    "# Catatan : Random Forest termasuk Bagging Ensemble (walau modified)\n",
    "!wget https://raw.githubusercontent.com/taufikedys/ScienCom/master/data/diabetes.csv\n",
    "file = 'diabetes.csv'\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_csv(file, names=names).values # Rubah ke numpy array\n",
    "X, Y = data[:,0:8], data[:,8] # Slice\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3)\n",
    "\n",
    "kNN = KNeighborsClassifier(3)\n",
    "kNN.fit(X_train, Y_train)\n",
    "Y_kNN = kNN.score(X_test, Y_test)\n",
    "\n",
    "DT = DecisionTreeClassifier(random_state=1)\n",
    "DT.fit(X_train, Y_train)\n",
    "Y_DT = DT.score(X_test, Y_test)\n",
    "\n",
    "NN = MLPClassifier(hidden_layer_sizes=(30,20, 10))# 2 layers 30 neurons and 20 neurons\n",
    "NN.fit(X_train, Y_train)\n",
    "y_NN = NN.score(X_test, Y_test)\n",
    "\n",
    "model = VotingClassifier(estimators=[('k-NN', kNN), ('Decision Tree', DT),('NN', NN)], voting='hard')\n",
    "model.fit(X_train,Y_train)\n",
    "Y_Vot = model.score(X_test,Y_test)\n",
    "\n",
    "print('Akurasi k-NN', Y_kNN)\n",
    "print('Akurasi Decision Tree', Y_DT)\n",
    "print('Akurasi NN', y_NN)\n",
    "print('Akurasi Votting', Y_Vot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging juga bisa digunakan di Klasifikasi (ndak hanya Regresi), \n",
    "# tapi kita pakai probabilitas dari setiap kategori\n",
    "T = DecisionTreeClassifier()\n",
    "K = KNeighborsClassifier()\n",
    "R= LogisticRegression()\n",
    "\n",
    "T.fit(X_train,Y_train)\n",
    "K.fit(X_train,Y_train)\n",
    "R.fit(X_train,Y_train)\n",
    "\n",
    "y_T=T.predict_proba(X_test)\n",
    "y_K=K.predict_proba(X_test)\n",
    "y_R=R.predict_proba(X_test)\n",
    "\n",
    "Ave = (y_T+y_K+y_R)/3\n",
    "print(Ave[:5]) # Print just first 5\n",
    "prediction = [v.index(max(v)) for v in Ave.tolist()]\n",
    "print(prediction[:5]) # Print just first 5\n",
    "print('Akurasi Averaging', accuracy_score(Y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost\n",
    "num_trees = 100\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=9)\n",
    "model = AdaBoostClassifier(n_estimators=num_trees, random_state=1)\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold)\n",
    "print(results.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Imbalance-Data\">Imbalance Data</h2>\n",
    "* Metric Trap\n",
    "* Akurasi kategori tertentu lebih penting\n",
    "* Contoh kasus\n",
    "<img alt=\"\" src=\"img/imbalance.png\" style=\"width: 400px ; height: 300px\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "\t<li>Undersampling</li>\n",
    "\t<li>Oversampling</li>\n",
    "\t<li>Model Based (weight adjustment)</li>\n",
    "</ul>\n",
    "<img alt=\"\" src=\"img/under-over-sampling.png\" style=\"width: 500px; height: 147px;\" />\n",
    "* https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets\n",
    "* Plot perbandingan: https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/combine/plot_comparison_combine.html#sphx-glr-auto-examples-combine-plot-comparison-combine-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh undersampling\n",
    "# jalankan perintah ini di terminal/command prompt: \n",
    "# \"pip install imblearn\" (Jupyter harus ditutup terlebih dahulu)\n",
    "\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_csv(file, names=names).values # Rubah ke numpy array\n",
    "X, Y = data[:,0:8], data[:,8].astype(int) # Slice\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "X, Y = make_imbalance(X, Y, sampling_strategy={0: 500, 1: 50},random_state=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3)\n",
    "\n",
    "print('Training target statistics: {}'.format(Counter(Y_train)))\n",
    "print('Testing target statistics: {}'.format(Counter(Y_test)))\n",
    "\n",
    "dSVM = svm.LinearSVC()\n",
    "dSVM.fit(X_train, Y_train)\n",
    "y_SVM = dSVM.predict(X_test); del dSVM\n",
    "print('Original Results:',classification_report(Y_test, y_SVM))\n",
    "\n",
    "nm = NearMiss(random_state=1)\n",
    "X_res, Y_res = nm.fit_resample(X_train, Y_train)\n",
    "dSVM = svm.LinearSVC()\n",
    "dSVM.fit(X_res, Y_res)\n",
    "y_SVM = dSVM.predict(X_test); del dSVM\n",
    "print('UnderSampling Results:\\n',classification_report_imbalanced(Y_test, y_SVM))\n",
    "\n",
    "sm = SMOTE(random_state=1)\n",
    "X_res, Y_res = sm.fit_resample(X_train, Y_train)\n",
    "dSVM = svm.LinearSVC()\n",
    "dSVM.fit(X_res, Y_res)\n",
    "y_SVM = dSVM.predict(X_test); del dSVM\n",
    "print('OverSampling Results:\\n',classification_report_imbalanced(Y_test, y_SVM))\n",
    "\n",
    "\n",
    "smo = SMOTEENN(random_state=1)\n",
    "X_res, Y_res = smo.fit_resample(X_train, Y_train)\n",
    "dSVM = svm.LinearSVC()\n",
    "dSVM.fit(X_res, Y_res)\n",
    "y_SVM = dSVM.predict(X_test)\n",
    "print('Combination Results:\\n',classification_report_imbalanced(Y_test, y_SVM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of model-based imbalance treatment - SVM\n",
    "n_samples_1, n_samples_2 = 1000, 100\n",
    "centers = [[0.0, 0.0], [2.0, 2.0]]\n",
    "clusters_std = [1.5, 0.5]\n",
    "X, y = make_blobs(n_samples=[n_samples_1, n_samples_2],centers=centers,cluster_std=clusters_std,random_state=0, shuffle=False)\n",
    "\n",
    "# fit the model and get the separating hyperplane\n",
    "clf = svm.SVC(kernel='linear', C=1.0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# fit the model and get the separating hyperplane using weighted classes\n",
    "wclf = svm.SVC(kernel='linear', class_weight={1: 10}) #WEIGHTED SVM\n",
    "wclf.fit(X, y)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolors='k')# plot the samples\n",
    "ax = plt.gca()# plot the decision functions for both classifiers\n",
    "xlim = ax.get_xlim(); ylim = ax.get_ylim()\n",
    "xx = np.linspace(xlim[0], xlim[1], 30)# create grid to evaluate model\n",
    "yy = np.linspace(ylim[0], ylim[1], 30)\n",
    "YY, XX = np.meshgrid(yy, xx)\n",
    "xy = np.vstack([XX.ravel(), YY.ravel()]).T\n",
    "Z = clf.decision_function(xy).reshape(XX.shape)# get the separating hyperplane\n",
    "a = ax.contour(XX, YY, Z, colors='k', levels=[0], alpha=0.5, linestyles=['-']) # plot decision boundary and margins\n",
    "Z = wclf.decision_function(xy).reshape(XX.shape)# get the separating hyperplane for weighted classes\n",
    "b = ax.contour(XX, YY, Z, colors='r', levels=[0], alpha=0.5, linestyles=['-'])# plot decision boundary and margins for weighted classes\n",
    "plt.legend([a.collections[0], b.collections[0]], [\"non weighted\", \"weighted\"], loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "data = pd.read_csv(file, names=names).values # Rubah ke numpy array\n",
    "X, Y = data[:,0:8], data[:,8].astype(int) # Slice\n",
    "X = preprocessing.StandardScaler().fit_transform(X)\n",
    "X, Y = make_imbalance(X, Y, sampling_strategy={0: 500, 1: 50},random_state=1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3)\n",
    "\n",
    "del T\n",
    "T = DecisionTreeClassifier(random_state = 0)\n",
    "T.fit(X_train,Y_train)\n",
    "y_DT = T.predict(X_test)\n",
    "print('Akurasi  (Decision tree Biasa) = ', accuracy_score(Y_test, y_DT))\n",
    "print(classification_report(Y_test, y_DT))\n",
    "\n",
    "del T\n",
    "T = DecisionTreeClassifier(class_weight = 'balanced', random_state = 0)\n",
    "T.fit(X_train,Y_train)\n",
    "y_DT = T.predict(X_test)\n",
    "print('Akurasi  (Weighted Decision tree) = ', accuracy_score(Y_test, y_DT))\n",
    "print(classification_report(Y_test, y_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img alt=\"\" src=\"img/clustering_Quotes.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Clustering?\n",
    "\n",
    "<p><img alt=\"\" src=\"img/5_what_is_clustering.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Definition\n",
    "\n",
    "Clustering is as a process of finding group structures within data such that each instance within a group is similar to one another and dissimilar to instances in other groups [1]\n",
    "\n",
    "[1]. Jain, A.K., Data clustering: 50 years beyond K-means. Pattern Recognition Letters, 2010. 31(8): p. 651-666."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Applications\n",
    "\n",
    "Clustering analysis applications can be divided into two broad categories, clustering for utility (e.g., data compression and indexing) and clustering for understanding data (e.g., finding latent structures or insights in the data) [2]. Methods developed in this subject (Data Mining) fall into the second category.\n",
    "\n",
    "[2]. Pang-Ning, T., M. Steinbach, and V. Kumar, Introduction to data mining. Vol. 74. 2006, Boston, MA, USA: Addison-Wesley Longman Publishing Co., Inc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Realworld Clustering Applications\n",
    "\n",
    "* Recommendation engines\n",
    "* Market segmentation\n",
    "* Social network analysis\n",
    "* Search result grouping\n",
    "* Medical imaging\n",
    "* Image segmentation\n",
    "* Anomaly detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p><img alt=\"\" src=\"img/56_Supervised VS unsupervised.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p><img alt=\"\" src=\"img/5_Clus-Clas.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<p><img alt=\"\" src=\"img/5_types_of_clustering.png\" style=\"height:500px; width:719px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Tantangan Clustering\n",
    "\n",
    "* Computational Complexity\n",
    "* Evaluation\n",
    "* Interpretation\n",
    "* Heavily depends on domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = df[['SEPALLEN','SEPALWID','PETALLEN','PETALWID']].values\n",
    "C = df['SPECIES'].values\n",
    "print(type(X), type(C))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Metode Clustering yang akan kita bahas:</h3>\n",
    "\n",
    "<ol>\n",
    "\t<li>k-Means</li>\n",
    "\t<li>k-Means++</li>\n",
    "\t<li>Mini-Batch k-Means</li>\n",
    "    <li>Hierarchical Clustering</li>\n",
    "    <li>DBSCAN</li>\n",
    "\t<li>Spectral</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>k-Means</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/5_Kmeans_animation.gif\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/5_kmeans_Algorithm.png\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works\n",
    "\n",
    "* Numerically\n",
    "* Visually: https://www.learndatasci.com/tutorials/k-means-clustering-algorithms-python-intro/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "\t<li>\n",
    "\t<h3>Apakah pengaruh menggunakan centroid dan algoritma ini terhadap hasil cluster?</h3>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<h3>k-Means tidak Robust terhadap outlier, Why? ==&gt; lalu apa yang sebaiknya dilakukan?</h3>\n",
    "\t</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means: http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans\n",
    "\n",
    "k = 3\n",
    "km = cluster.KMeans(n_clusters=k, init='random', max_iter=300, tol=0.0001, n_jobs=-1, random_state = 33)\n",
    "km.fit(X)\n",
    "'Done'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hasil clusteringnya\n",
    "C_km = km.predict(X)\n",
    "C_km\n",
    "# Apa beda label ini dengan klasifikasi (\"labels\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p= sns.countplot(C_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2D = umap.UMAP(n_neighbors=5, min_dist=0.3).fit_transform(X)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2D[:,0], X2D[:,1], c=C_km)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Does imbalance data matters?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "TS.km_assumptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"k-Means++\">k-Means++</h3>\n",
    "\n",
    "<p>Original <em>k-means</em> memulai algoritmanya dengan mengacak centroid awal dan k-means tidak &quot;robust&quot; terhadap centroid awal ini (apa artinya?).</p>\n",
    "\n",
    "<p><strong>k-Means akan menghasilkan hasil yang berbeda-beda jika di-run beberapa kali!....</strong></p>\n",
    "\n",
    "<p>k-Means++ &quot;mengatasi&quot; hal ini:</p>\n",
    "\n",
    "<p>inisialisasi centroid tidak random, tapi dengan menghitung probabilitas terbaik bagi centroid awal.</p>\n",
    "\n",
    "<p>Keuntungan selain lebih robust, biasanya iterasi yang dibutuhkan jauh lebih sedikit ketimbang k-means++</p>\n",
    "\n",
    "<p>Reference :&nbsp;<a href=\"http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf\" target=\"_blank\">http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf</a>&nbsp;</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means++ clustering http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "kmPP = cluster.KMeans(n_clusters=k, init='k-means++', max_iter=300, tol=0.0001, n_jobs=-1, random_state = random_state)\n",
    "kmPP.fit(X)\n",
    "C_kmpp = kmPP.predict(X)\n",
    "\n",
    "sns.countplot(C_kmpp)\n",
    "C_kmpp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2D[:,0], X2D[:,1], c=C_kmpp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mini-Batch k-Means:</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/5_minibatch.JPG\" /></p>\n",
    "\n",
    "<p><strong>Referensi</strong>: *Sculley, D. (2010, April). Web-scale k-means clustering. In&nbsp;<em>Proceedings of the 19th international conference on World wide web</em>&nbsp;(pp. 1177-1178). ACM.</p>\n",
    "\n",
    "<p>* Google</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniBatch k-Means \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cluster.MiniBatchKMeans.html\n",
    "# minibatch \"tidak bisa parallel\"!!!...\n",
    "# parameter penting km = batch_size ... pada aplikasi sesungguhnya disarankan \"minimal\" 3xk\n",
    "mbkm = cluster.MiniBatchKMeans(n_clusters=3, init='random', max_iter=300, tol=0.0001, random_state = random_state) \n",
    "mbkm.fit(X)\n",
    "C_mbkm = mbkm.predict(X)\n",
    "sns.countplot(C_mbkm)\n",
    "C_mbkm[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2D[:,0], X2D[:,1], c=C_mbkm)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MiniBatch k-Means++\n",
    "mbkmPP = cluster.MiniBatchKMeans(n_clusters=k, init='k-means++', max_iter=300, tol=0.0001, random_state = random_state) \n",
    "mbkmPP.fit(X)\n",
    "C_mbkmPP = mbkmPP.predict(X)\n",
    "sns.countplot(C_mbkmPP)\n",
    "C_mbkmPP[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2D[:,0], X2D[:,1], c=C_mbkmPP)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k_means VS MiniBatch k-Means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS.km_vs_mbkm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perbedaan Randomized VS k-Means++ - Initialization Matters\n",
    "\n",
    "* n_init = Number of time the k-means algorithm will be run with different centroid seeds. The final results will be the best output of n_init consecutive runs in terms of inertia.\n",
    "* inertia = Sum of squared distances of samples to their closest cluster center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS.km_initializations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluasi dan interpretasi k-Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Silhouette-Coefficient\">Silhouette Coefficient</h2>\n",
    "\n",
    "<img alt=\"\" src=\"img/silhouette.png\" />\n",
    "\n",
    "* Apa makna intuitifnya?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluasi : Internal . Contoh Silouette Coefficient ==> warning hanya cocok untuk k-means (centroid-based clustering)\n",
    "Hasil_Clustering = [C_km, C_kmpp, C_mbkm, C_mbkmPP]\n",
    "for res in Hasil_Clustering:\n",
    "    print(siluet(X,res), end=', ')\n",
    "# Bagaimana cara kerja dan interpretasinya?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Evaluasi Clustering: Internal VS External</strong></p>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/5_Clustering_evaluation.jpg\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagaimana dengan evaluasi External?\n",
    "# \"C\" adalah ground truth/golden standard\n",
    "for res in Hasil_Clustering:\n",
    "    print(purity(C,res), end=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi External NMI \n",
    "\n",
    "for res in Hasil_Clustering:\n",
    "    print(NMI(C,res), end=', ')\n",
    "# untuk F-Score ada juga code dan penjelasannya di blog post di atas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please read more here:  https://taufiksutanto.blogspot.co.id/2017/11/evaluasi-eksternal-clustering-pairwise.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Number of Clusters? - Elbow Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distorsions, k1, kN = [], 2, 10\n",
    "for k in range(k1, kN):\n",
    "    kmeans = cluster.KMeans(n_clusters=k).fit(X)\n",
    "    distorsions.append(kmeans.inertia_)\n",
    "\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "plt.plot(range(k1, kN), distorsions); plt.grid(True)\n",
    "plt.title('Elbow curve')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Number of Cluster based on Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS.sil_based_optimal_km()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluasi sebenarnya tidak terlalu penting di Unsupervised learning.\n",
    "# inilah yang membedakan \"clustering\" dan \"clustering Analysis\"\n",
    "# yang lebih penting adalah interpretasi, tapi Bagaimana?\n",
    "# contoh k-means\n",
    "centroids = kmPP.cluster_centers_\n",
    "centroids # perhatikan ada k centroids, karena ada k cluster\n",
    "print(centroids[0].shape)\n",
    "centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best/Optimal Clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catatan Penting dalam mengevaluasi Clustering secara internal:\n",
    "\n",
    "* Tidak ada clustering yang \"benar\"\n",
    "* Yang terpenting adalah interpretability/Informasi yang didapatkan (non-trivial information)\n",
    "* Internal metric tertentu hanya cocok untuk suatu algoritma tertentu juga, sehingga di Penelitian/Aplikasi di dunia professional jangan membandingkan 2 macam clustering dengan ukuran internal yang spesifik untuk metode clustering tertentu (misal Silhouette untuk k-Means).\n",
    "* Kleinberg, J. M. (2003). An impossibility theorem for clustering. In Advances in neural information processing systems (pp. 463-470).\n",
    "* Referensi 1: http://papers.nips.cc/paper/2340-an-impossibility-theorem-for-clustering.pdf\n",
    "* Referensi 2: https://core.ac.uk/download/pdf/34638775.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "<p><img alt=\"\" src=\"img/5_hierarchical.gif\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/5_linkages.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hierarchical http://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering\n",
    "hierarchical = cluster.AgglomerativeClustering(n_clusters=3, linkage='average')\n",
    "hierarchical.fit(X) # Lambat .... dan menggunakan banyak memori O(N^2 log(N))\n",
    "C_h = hierarchical.labels_.astype(np.int)\n",
    "C_h[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/5_Hierarchical_Text_Clustering_in_Genes_penyakit.jpg\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TS.compare_linkages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linkages Comparisons\n",
    "\n",
    "* single linkage is fast, and can perform well on non-globular data, but it performs poorly in the presence of noise.\n",
    "* average and complete linkage perform well on cleanly separated globular clusters, but have mixed results otherwise.\n",
    "* Ward is the most effective method for noisy data.\n",
    "* http://scikit-learn.org/stable/auto_examples/cluster/plot_linkage_comparison.html#sphx-glr-auto-examples-cluster-plot-linkage-comparison-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dendogram Example\n",
    "# http://seaborn.pydata.org/generated/seaborn.clustermap.html\n",
    "df.pop('SPECIES')\n",
    "g = sns.clustermap(df, method=\"single\", metric=\"euclidean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DBSCAN\n",
    "\n",
    "<p><img alt=\"\" src=\"img/5_DBSCAN.gif\" /></p>\n",
    "\n",
    "<p>Karena algoritma (cara kerjanya) ini maka DBSCAN sering digunakan untuk (multivariate) outlier detection.</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBSCAN http://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html\n",
    "# tidak membutuhkan input parameter k!!!... sangat diperlukan untuk text Mining ... atau clustering data yang besar\n",
    "dbscan = cluster.DBSCAN(eps=0.7, min_samples=5, metric='euclidean')\n",
    "dbscan.fit(X)\n",
    "C_db = dbscan.labels_.astype(np.int)\n",
    "sns.countplot(C_db)\n",
    "C_db[:10]\n",
    "# apa makna cluster label -1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum([1 for i in C_db if i==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2D[:,0], X2D[:,1], c=C_db)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Spectral Clustering</h3>\n",
    "\n",
    "<ol>\n",
    "\t<li>Butuh matrix similarity S = S(xi,xj)</li>\n",
    "\t<li>S menjadi Graph tidak berarah</li>\n",
    "\t<li>Karena baris=kolom dan simetris ==&gt; positive definite</li>\n",
    "\t<li>Karena positive definite ==&gt; eigenvalue real</li>\n",
    "\t<li>Eigenvalue dari matrix ini == Spectral Teory :&nbsp;https://en.wikipedia.org/wiki/Spectral_graph_theory&nbsp;</li>\n",
    "\t<li>Maknanya adalah seperti &quot;centrality analysis&quot; di Social media Analytic, yaitu:<br />\n",
    "\tmembentuk cluster graph sedemikian sehingga di suatu cluster tertentu weight (konektivitas)-nya paling besar.</li>\n",
    "</ol>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/5_Spectral_graph.png\" /></p>\n",
    "\n",
    "\n",
    "<p><u><strong>referensi</strong></u>:&nbsp;Ng, A. Y., Jordan, M. I., &amp; Weiss, Y. (2002). On spectral clustering: Analysis and an algorithm. In&nbsp;<em>Advances in neural information processing systems</em>&nbsp;(pp. 849-856).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://www.youtube.com/watch?v=zkgm0i77jQ8\n",
    "* <video controls src=\"img/SpectralClustering.MP4\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Karenanya Spectral bisa mengelompokkan data yang tidak &quot;spherical&quot; (bulat seperti k-means)</p>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/5_Spectral_kmeans.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral : http://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html\n",
    "\n",
    "spectral = cluster.SpectralClustering(n_clusters=3)\n",
    "spectral.fit(X)\n",
    "C_spec = spectral.labels_.astype(np.int)\n",
    "sns.countplot(C_spec)\n",
    "C_spec[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X2D[:,0], X2D[:,1], c=C_spec)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/5_clustering_benchmarks.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/5_Cluster_yg_mana.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Computational-Complexity-Challenge-of-Clustering\">Computational Complexity Challenge of Clustering</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/clustering_efficiency.png\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> End of Workshop.\n",
    "\n",
    "<hr />\n",
    "<img alt=\"\" src=\"img/1_BigData_MeMe.png\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
