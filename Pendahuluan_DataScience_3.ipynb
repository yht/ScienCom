{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<center><img alt=\"\" src=\"img/Cover_ScienCom.jpg\"/></center> \n",
    "<center><h1><strong>Dr. Taufik Sutanto, MScTech</strong></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=\"blue\">Akses Modul di:\n",
    "\n",
    "## Pendahuluan & EDA: https://bit.ly/sciencom-30okt2019\n",
    "## Machine Learning: https://bit.ly/sciencom-30okt2019-2\n",
    "## Text Mining & SMA: https://bit.ly/sciencom-30okt2019-3\n",
    "## Unduh seluruh module hari ini di : http://bit.ly/sciencom-modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <font color=\"blue\">Outline:</font>\n",
    "\n",
    "* Diskusi tentang **NLP, Text Analytics, & Text Mining**\n",
    "  (dengan penerapan ke social media analytics)\n",
    "* **Social Media & Network Analytics**\n",
    " - Community Detection\n",
    " - Partition Analysis\n",
    " - Centrality Analysis\n",
    " - Advanced Visualization\n",
    " - Sentiment Analysis\n",
    " - Topic Modelling\n",
    "* **Diskusi**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Modules untuk Notebook ini\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "!pip install unidecode\n",
    "!pip install pyLDAvis\n",
    "!pip install textblob\n",
    "!pip install sastrawi\n",
    "!pip install spacy\n",
    "!python -m spacy download en\n",
    "!python -m spacy download xx\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n",
    "try:\n",
    "    !wget https://raw.githubusercontent.com/taufikedys/Graph-Python-Nx/master/taudata.py\n",
    "    !wget https://github.com/taufikedys/Graph-Python-Nx/blob/master/data.html\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import taudata as tau\n",
    "\n",
    "import time, numpy as np, matplotlib.pyplot as plt, networkx as nx, pandas as pd, seaborn as sns, graphviz, pyLDAvis, pyLDAvis.sklearn\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from graphviz import Digraph\n",
    "from textblob import TextBlob\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from spacy.lang.id import Indonesian\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "nlp_id = Indonesian()  # Language Model\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "stemmer = StemmerFactory().create_stemmer()\n",
    "pyLDAvis.enable_notebook()\n",
    "sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Text Mining dan NLP?\n",
    "<p>Natural Language Processing (NLP) - Pemrosesan Bahasa Alami (PBA):&nbsp;</p>\n",
    "\n",
    "<p>\n",
    "&quot;<big><em>Sebuah cabang ilmu&nbsp;(AI/Computational Linguistik) yang mempelajari bagaimana&nbsp;bahasa (alami) manusia (terucap/tertulis) dapat dipahami dengan baik oleh komputer dan komputer dapat merespon dengan cara yang serupa ke manusia</em></big>&quot;.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><img alt=\"\" src=\"img/1_jarvis.jpg\" style=\"height: 450px; width: 600px;\" /></p>\n",
    "\n",
    "<p><a href=\"https://www.turn-on.de/lifestyle/topliste/zehn-film-gadgets-die-wir-uns-im-wahren-leben-wuenschen-4413\" target=\"_blank\"><strong>[Image Source]</strong></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><strong>Aplikasi Umum NLP:</strong></p>\n",
    "\n",
    "<ol>\n",
    "\t<li>Machine Translation (Misal&nbsp;https://translate.google.com/ )</li>\n",
    "\t<li>Information Retrieval (IR)&nbsp;(misal www.google.com, bing, elasticsearch, etc.)</li>\n",
    "\t<li>Man-Machine Interface (misal Siri, cortana, atau Alexa)</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><strong>Apakah Perbedaan antara NLP dan Text Mining (TM)?</strong></p>\n",
    "\n",
    "<p>TM (terkadang disebut Text Analytics) adalah sebuah pemrosesan teks (biasanya dalam skala besar) untuk menghasilkan (generate) informasi atau insights. Untuk menghasilkan informasi TM menggunakan beberapa metode, termasuk NLP. TM mengolah teks secara eksplisit, sementara NLP mencoba mencari makna latent (tersembunyi) lewat aturan bahasa (e.g. grammar/idioms/Semantics).<br />\n",
    "<strong>Contoh aplikasi TM</strong> : Clustering, Klasifikasi, Social Media Analytics (SMA).</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenisasi\n",
    "\n",
    "<p>Tokenisasi adalah pemisahan kata, simbol, frase, dan entitas penting lainnya (yang disebut sebagai token) dari sebuah teks untuk kemudian di analisa lebih lanjut. Token dalam NLP sering dimaknai dengan &quot;sebuah kata&quot;, walau tokenisasi juga bisa dilakukan ke kalimat, paragraf, atau entitas penting lainnya (misal suatu pola string DNA di Bioinformatika).</p>\n",
    "\n",
    "<p><strong>Mengapa perlu tokenisasi?</strong></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Langkah penting dalam preprocessing, menghindari kompleksitas mengolah langsung pada string asal.</li>\n",
    "\t<li>Menghindari masalah (semantic) saat pemrosesan model-model natural language.</li>\n",
    "\t<li>Suatu tahapan sistematis dalam merubah unstructured (text) data ke bentuk terstruktur yang lebih mudah di olah.</li>\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"img\\2_Pipeline_Tokenization.png\" style=\"height:300px; width:768px\" /><br />\n",
    "[<a href=\"https://www.softwareadvice.com/resources/what-is-text-analytics/\" target=\"_blank\"><strong>Image Source</strong></a>]</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tokenisasi dengan <font color=\"blue\"> TextBlob</font>\n",
    "<strong>Kelebihan</strong>:</p>\n",
    "<ol>\n",
    "\t<li>Sederhana &amp; mudah untuk digunakan/pelajari.</li>\n",
    "\t<li>Textblob objects punya behaviour/properties yang sama dengan string di Python.</li>\n",
    "\t<li>TextBlob dibangun dari kombinasi modul NLTK dan (Clips) Pattern</li>\n",
    "</ol>\n",
    "\n",
    "<p><strong>Kekurangan</strong>:</p>\n",
    "<ol>\n",
    "\t<li>Tidak secepat Spacy dan NLTK</li>\n",
    "\t<li>Language Model terbatas: English, German, French</li>\n",
    "</ol>\n",
    "\n",
    "<p>*Blob : Binary large Object</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenizing di TextBlob\n",
    "\n",
    "T = \"Hello, Mr. Man. He smiled!! This, i.e. that, is it.\"\n",
    "print(TextBlob(T).words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tokenisasi tidak hanya language dependent, tapi juga environment dependent\n",
    "\n",
    "<p>Tokenization sebenarnya tidak sesederhana memisahkan berdasarkan spasi dan removing symbol. Sebagai contoh dalam bahasa Jepang/Cina/Arab suatu kata bisa terdiri dari beberapa karakter.</p>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/2_Tokenization_Complexity.jpg\" style=\"height:500px; width:686px\" /><br />\n",
    "[<a href=\"http://aclweb.org/anthology/Y/Y11/Y11-1038.pdf\" target=\"_blank\"><strong>Image Source</strong></a>]</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Contoh Tokenizer untuk twitter\n",
    "\n",
    "Tokenizer = TweetTokenizer(strip_handles=False, reduce_len=False)\n",
    "tweet = \"@Kirana_Sutanto I am so happpppppppy\"\n",
    "print(Tokenizer.tokenize(tweet))\n",
    "\n",
    "# Masih salah (i.e. \"happpy\"), nanti kita akan perbaiki ini dengan \"spell check\"\n",
    "# catatan: pada permasalahan \"Sentiment analysis\" kata yang ditulis panjang seperti diatas \n",
    "# bisa mengindikasikan sentiment yang kuat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Tokenisasi (NLP) Bahasa Indonesia:\n",
    "\n",
    "<p>NLTK belum support Bahasa Indonesia, bahkan module NLP Python yang support bahasa Indonesia secara umum masih sangat langka. Beberapa <u><strong>resources </strong></u>yang dapat digunakan:</p>\n",
    "\n",
    "<ol>\n",
    "\t<li><strong><a href=\"https://github.com/kirralabs/indonesian-NLP-resources\" target=\"_blank\">KirraLabs</a></strong>: Mix of NLP-TextMining resources</li>\n",
    "\t<li><strong><a href=\"https://pypi.python.org/pypi/Sastrawi/1.0.1\" target=\"_blank\">Sastrawi 1.0.1</a>:</strong>&nbsp;untuk &quot;stemming&quot; &amp;&nbsp;<strong><a href=\"https://devtrik.com/python/stopword-removal-bahasa-indonesia-python-sastrawi/\" target=\"_blank\">stopwords&nbsp;</a></strong>bahasa Indonesia.</li>\n",
    "\t<li><strong><a href=\"http://stop-words-list-bahasa-indonesia.blogspot.co.id/2012/09/daftar-kata-dasar-bahasa-indonesia.html\" target=\"_blank\">Daftar Kata Dasar Indonesia</a></strong>:&nbsp;Bisa di load sebagai dictionary di Python</li>\n",
    "\t<li><strong><a href=\"https://id.wiktionary.org/wiki/Wiktionary:ProyekWiki_bahasa_Indonesia/Daftar_kata\" target=\"_blank\">Wiktionary</a></strong>: ProyekWiki bahasa Indonesia [termasuk Lexicon]</li>\n",
    "\t<li><a href=\"http://wn-msa.sourceforge.net/\" target=\"_blank\"><strong>WordNet Bahasa Indonesia</strong></a>: Bisa di load&nbsp;sebagai dictionary (atau NLTK<em>*</em>) di Python.</li>\n",
    "\t<li><strong><a href=\"http://kakakpintar.com/daftar-kata-baku-dan-tidak-baku-a-z-dalam-bahasa-indonesia/\" target=\"_blank\">Daftar Kata Baku-Tidak Baku</a></strong>: Bisa di load sebagai dictionary di Python.</li>\n",
    "\t<li><strong><a href=\"https://spacy.io/\" target=\"_blank\">Spacy</a></strong>: Cepat/efisien, MIT License, tapi language model Indonesia masih terbatas.</li>\n",
    "\t<li><a href=\"http://ufal.mff.cuni.cz/udpipe\" target=\"_blank\"><strong>UdPipe</strong></a>: Online request &amp; restricted license (support berbagai bahasa -&nbsp;pemrograman).</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Contoh Tokenisasi dalam bahasa Indonesia dengan Spacy\n",
    "\n",
    "teks = 'Sore itu, Hamzah melihat kupu-kupu di taman. Ibu membeli oleh-oleh di pasar'\n",
    "tokenS_id = nlp_id(teks)\n",
    "#T = []\n",
    "#for token in tokenS_id:\n",
    "#    T.append(token)\n",
    "print([t for t in tokenS_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><u><big><strong>Word Case</strong></big></u><big> (Huruf BESAR/kecil):</big></p>\n",
    "\n",
    "<ul>\n",
    "\t<li>Untuk menganalisa makna (<em>semantic</em>) dari suatu (frase) kata dan mencari informasi dalam proses textmining, seringnya (*) kita tidak membutuhkan informasi huruf besar/kecil dari kata&nbsp;tersebut.</li>\n",
    "\t<li><em>Text case normaliation</em> dapat dilakukan pada string secara efisien tanpa melalui tokenisasi (mengapa?).</li>\n",
    "\t<li>Namun, bergantung pada analisa teks yang akan digunakan pengguna harus berhati-hati dengan urutan proses (pipelining) dalam preprocessing. Mengapa dan apa contohnya?</li>\n",
    "</ul>\n",
    "\n",
    "<p>(*) Coba temukan minimal 2 pengecualian dimana&nbsp; huruf kapital/kecil (case) mempengaruhi makna/pemrosesan teks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Ignore case (huruf besar/kecil)\n",
    "T = \"Hi there!, I am a data professional. Nice to meet you :)\"\n",
    "print(T.lower())\n",
    "print(T.upper())\n",
    "# Perintah ini sangat efisien karena hanya merubah satu bit di setiap (awal) bytes dari setiap karakter\n",
    "# Sehingga tetap efisien jika ingin dilakukan sebelum tokenisasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Stemming dan Lemma</font>\n",
    "\n",
    "<ol>\n",
    "\t<li>\n",
    "\t<p><strong>Stemmer</strong>&nbsp;akan menghasilkan sebuah bentuk kata yang disepakati oleh suatu sistem tanpa mengindahkan konteks kalimat. Syaratnya beberapa kata dengan makna serupa hanya perlu dipetakan secara konsisten ke sebuah kata baku.&nbsp;Banyak digunakan di IR &amp;&nbsp;komputasinya relatif sedikit. Biasanya dilakukan dengan menghilangkan imbuhan (suffix/prefix).</p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p><strong>lemmatisation</strong> akan menghasilkan kata baku (dictionary word) dan bergantung konteks.</p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p>Lemma &amp; stemming bisa jadi sama-sama menghasilkan suatu akar kata (root word). Misal : <em>Melompat </em>==&gt; <em>lompat</em></p>\n",
    "\t</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Mengapa melakukan Stemming &amp; Lemmatisasi</strong>?</p>\n",
    "\n",
    "<ol>\n",
    "\t<li>Sering digunakan di IR (Information Retrieval) agar ketika seseorang mencari kata tertentu, maka seluruh kata yang terkait juga diikutsertakan.<br />\n",
    "\tMisal:&nbsp;<em>organize</em>,&nbsp;<em>organizes</em>, and&nbsp;<em>organizing&nbsp;</em>&nbsp;dan&nbsp;<em>democracy</em>,&nbsp;<em>democratic</em>, and&nbsp;<em>democratization</em>.</li>\n",
    "\t<li>Di Text Mining Stemming dan Lemmatisasi akan mengurangi dimensi (mengurangi variasi morphologi), yang terkadang akan meningkatkan akurasi.</li>\n",
    "\t<li>Tapi di IR efeknya malah berkebalikan: <strong><font color=\"blue\">meningkatkan recall, tapi menurunkan akurasi&nbsp;</font></strong>[<a href=\"https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html\" target=\"_blank\"><strong>Link</strong></a>]. Contoh: kata&nbsp;<em>operate, operating, operates, operation, operative, operatives, dan operational</em>&nbsp;jika di stem menjadi <em>operate</em>, maka ketika seseorang mencari &quot;<em>operating system</em>&quot;, maka entry seperti&nbsp;<em>operational and research</em> dan&nbsp;<em>operative and dentistry</em>&nbsp;akan muncul sebagai entry dengan relevansi yang cukup tinggi.</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p><strong>Stemming tidak perlu &quot;benar&quot;, hanya perlu konsisten. Sehingga memiliki berbagai variansi, (sebagian) contoh di NLTK:</strong></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizer dengan Sastrawi\n",
    "\n",
    "I = \"perayaan itu Berbarengan dengan saat kita bepergian ke Makassar\"\n",
    "print(stemmer.stem(I))\n",
    "print(stemmer.stem(\"Perayaan Bepergian Menyuarakan\"))\n",
    "# Ada beberapa hal yang berbeda antara Sastrawi dan modul-modul diatas.\n",
    "# Apa sajakah?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3 id=\"Tips:\">Tips:</h3>\n",
    "\n",
    "<ul>\n",
    "\t<li>Secara umum &#39;biasanya&#39; di Text Mining yang kita butuhkan hanyalah <strong><font color=\"blue\">Lemma</font></strong>.</li>\n",
    "\t<li>&quot;Kecuali&quot; di aplikasi IR, spelling correction, variasi kata, clustering, atau terkadang klasifikasi. Pada aplikasi-aplikasi tersebut stemming terkadang lebih diinginkan.</li>\n",
    "\t<li>Stemming jauh lebih cepat, tapi tidak selalu tersedia di modul NLP.</li>\n",
    "\t<li>Beberapa algoritma tertentu membutuhkan tanda &quot;.&quot; dan &quot;,&quot; : contohnya untuk document summarization di textRank.</li>\n",
    "\t<li>&quot;_&quot; juga biasa digunakan untuk menyatakan frase kata di representasi n-grams (misal &quot;buah_tangan&quot;).</li>\n",
    "\t<li>Stemming juga digunakan pada Word Sense Disambiguation (WSD)</li>\n",
    "</ul>\n",
    "\n",
    "<h3 id=\"Diskusi:\">Diskusi:</h3>\n",
    "\n",
    "<ul>\n",
    "\t<li>Untuk menghemat storage database, apakah sebaiknya kita menyimpan saja hasil preprocessed texts/documents?</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Butuh koneksi internet\n",
    "\n",
    "categories = ['sci.med', 'talk.politics.misc',  'rec.autos']\n",
    "data = fetch_20newsgroups(subset='train', categories=categories,remove=('headers', 'footers', 'quotes'))\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh cara mengakses datanya\n",
    "print( type(data) )\n",
    "print(dir(data))\n",
    "print(data.data[0]) # Dokumen pertama\n",
    "print(data.target_names[0]) # Dokumen pertama\n",
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rubah struktur data diatas ke dalam bentuk struktur data sederhana: \"list of documents\"\n",
    "Y = data.target # List: 0 = class 1, 1 = class 2, ... dst\n",
    "print('Contoh Label 3 dokumen pertama: ',Y[:3])\n",
    "X = [doc for doc in data.data] # setiap elemen dalam list adalah dokumen\n",
    "X[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Vector-Space-Model---VSM\">Vector Space Model - VSM</h1>\n",
    "\n",
    "<ul>\n",
    "\t<li>Data yang biasanya kita ketahui berbentuk <strong>tabular </strong>(tabel/kolom-baris/matriks/<em>array</em>/larik), data seperti ini disebut data terstruktur (<strong><em>structured data</em></strong>).</li>\n",
    "\t<li>Data terstruktur dapat disimpan dengan baik di&nbsp;<em>spreadsheet</em>&nbsp;(misal:&nbsp;<em>Excel/CSV</em>) atau basis data (<em>database</em>) relasional dan secara umum dapat digunakan langsung oleh berbagai model/<em>tools</em>&nbsp;statistik/data mining konvensional.</li>\n",
    "\t<li>Sebagian data yang lain memiliki &ldquo;<em>tags</em>&rdquo; yang menjelaskan elemen semantik yang berbeda di dalamnya dan cenderung tidak memiliki skema (struktur) yang statis.</li>\n",
    "\t<li>Data seperti ini disebut data<em>&nbsp;<strong>semi-structured</strong></em>, contohnya data dalam bentuk &nbsp;<strong><a href=\"http://www.w3.org/XML/\" target=\"_blank\">XML</a></strong>.</li>\n",
    "\t<li>Apa bedanya? Apa maksudnya tidak memiliki skema yang statis? Penjelasan mudahnya bayangkan sebuah data terstruktur (tabular), namun dalam setiap baris (<em>record/instance</em>)-nya tidak memiliki jumlah variabel (peubah) yang sama.</li>\n",
    "\t<li>Tentu saja data seperti ini tidak sesuai jika disimpan dan diolah dengan&nbsp;<em>tools/software</em>&nbsp;yang mengasumsikan struktur yang statis pada setiap barisnya (misal: Excel dan SPSS).</li>\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/3_tipeData.png\" style=\"height: 400px ; width: 430px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "\t<li>Data multimedia seperti teks, gambar atau video <strong>tidak dapat</strong>&nbsp;<strong>secara langsung</strong>&nbsp;dianalisa dengan model statistik/data mining.</li>\n",
    "\t<li>Sebuah proses awal&nbsp;<em>(pre-process)</em>&nbsp;harus dilakukan terlebih dahulu untuk merubah data-data tidak (semi) terstruktur tersebut menjadi bentuk yang dapat digunakan oleh model statistik/data mining konvensional.</li>\n",
    "\t<li>Terdapat berbagai macam cara mengubah data-data tidak terstruktur tersebut ke dalam bentuk yang lebih sederhana, dan ini adalah suatu bidang ilmu tersendiri yang cukup dalam. Sebagai contoh saja sebuah teks biasanya dirubah dalam bentuk vektor/<em>topics</em>&nbsp;terlebih dahulu sebelum diolah.</li>\n",
    "\t<li>Vektor data teks sendiri bermacam-macam jenisnya: ada yang berdasarkan eksistensi (<strong><em>binary</em></strong>), frekuensi dokumen (<strong>tf</strong>), frekuensi dan invers jumlah dokumennya dalam corpus (<strong><a href=\"https://en.wikipedia.org/wiki/Tf%E2%80%93idf\" target=\"_blank\">tf-idf</a></strong>), <strong>tensor</strong>, dan sebagainya.</li>\n",
    "\t<li>&nbsp;Proses perubahan ini sendiri biasanya tidak&nbsp;<em>lossless</em>, artinya terdapat cukup banyak informasi yang hilang. Maksudnya bagaimana? Sebagai contoh ketika teks direpresentasikan dalam vektor (sering disebut sebagai model <strong>bag-of-words</strong>) maka informasi urutan antar kata menghilang.&nbsp;</li>\n",
    "</ul>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/3_structureData.png\" style=\"height:270px; width:578px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>Contoh bentuk umum representasi dokumen:</strong></p>\n",
    "\n",
    "\n",
    "<p><img alt=\"\" src=\"img/3_Bentuk umum representasi dokumen.JPG\" style=\"height: 294px ; width: 620px\" /></p>\n",
    "\n",
    "<p>Pada Model <em>n-grams</em> kolom bisa juga berupa frase.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Document-Term-Matrix-:-Vector-Space-Model---VSM\">Document-Term Matrix : Vector Space Model - VSM</h2>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/vsm_matrix.png\" style=\"width: 500px; height: 283px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf:\n",
    "* Menurut http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html\n",
    "* default formula tf-idf yang digunakan sk-learn adalah:\n",
    "* $tfidf = tf * log(\\frac{N}{df+1})$ ==> Smooth IDF\n",
    "* namun kita merubahnya menjadi:\n",
    "* $tfidf = tf * log(\\frac{N}{df})$ ==> Non Smooth IDF\n",
    "* $tfidf = tf * log(\\frac{N}{df+1})$ ==> linear_tf, Smooth IDF\n",
    "* $tfidf = (1+log(tf)) * log(\\frac{N}{df})$ ==> sublinear_tf, Non Smooth IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menggunakan modul SciKit untuk merubah data tidak terstruktur ke VSM\n",
    "# Scikit implementation http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html#sklearn.feature_extraction.text.TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VSM term Frekuensi : \"tf-idf\"\n",
    "tfidf_vectorizer = TfidfVectorizer(smooth_idf= False, sublinear_tf=True, lowercase=True, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diskusi Curse of Dimensionality\n",
    "\n",
    "<p><img alt=\"\" src=\"img/chd_1.PNG\" style=\"width: 600px; height: 282px;\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VSM term Frekuensi : \"tf-idf\"\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=5, smooth_idf= False, sublinear_tf=True, lowercase=True, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "print(tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kelemahan lain VSM?\n",
    "\n",
    "## nGram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VSM term Frekuensi : \"tf-idf\"\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_df=0.90, min_df=5, smooth_idf= False, sublinear_tf=True, lowercase=True, stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(X)\n",
    "\n",
    "print(tfidf.shape)\n",
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teknik lain : Word Embeddings\n",
    "\n",
    "<p><img alt=\"\" src=\"img/3_word2vec_example.png\" style=\"height:400px; width:667px\" /></p>\n",
    "<p><img alt=\"\" src=\"img/3_word2Vec.png\" style=\"height:400px; width:636px\" /><br />\n",
    "Dikembangkan oleh Tomas Mikolov - Google :</p>\n",
    "\n",
    "<p>Goldberg, Yoav; Levy, Omer. &quot;word2vec Explained: Deriving Mikolov et al.&#39;s Negative-Sampling Word-Embedding Method&quot;.&nbsp;<a href=\"https://en.wikipedia.org/wiki/ArXiv\">arXiv</a>:<a href=\"https://arxiv.org/abs/1402.3722\">1402.3722</a> </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Ketika mengolah dokumen (file dalam bentuk teks), harapan kita seperti ini:</h3>\n",
    "\n",
    "<img alt=\"\" src=\"img/4_harapan_LSA.png\" style=\"height:99px; width:198px\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Namun kita sudah bahas kemarin kenyataannya seperti ini:</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/4_kenyataan_LSA.png\" style=\"height:183px; width:182px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling\n",
    "\n",
    "<p><img alt=\"\" src=\"img/topic_modelling.png\" /></p>\n",
    "\n",
    "<p><strong><big>Tapi bukan seperti klasifikasi dan bukan berarti kata-kata Sport, Technology, dan Entertainment dominan di kategori-kategori tersebut. Topic modelling lebih ke soft-clustering, dimana suatu dokumen dimasukkan ke dalam beberapa cluster (topic) sekaligus. Adapun nama &quot;topic/cluster&quot;-nya di interpretasi dari kata-kata yang ada didalamnya.</big></strong></p>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/LDA_Distributions.png\" /></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mari kita dalami lebih jauh Topic Pembicaraan ini\n",
    "tf, tm, vec = tau.getTopics(X, n_topics=3, Top_Words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.sklearn.prepare(tf, tm, vec) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diskusi Topic Modelling\n",
    "\n",
    "## hati-hati ... Rumus LDA menggunakan perhitungan probabilitas kemunculan. Apa akibatnya?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Graph-From-Social-media\">Graph From Social media</h1>\n",
    "\n",
    "<h3 id=\"Mentions,-Followers,-Friends\">Mentions, Followers, Friends</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/SNA_Graph_Types.png\" style=\"width: 700px; height: 443px;\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">Outline Social Media Analytic:</font>\n",
    "* Pendahuluan SMA\n",
    "* Crawling tanpa API dan Data masa lalu (> 7 hari)\n",
    "* Simple (but powerful) Analisis - Voyant Tools\n",
    "* Sentiment Analysis\n",
    "* Simple Graph Analysis: Community dan Centrality Analysis\n",
    "* Combining Graph &amp; Text Analysis: Topic Modelling &amp; Community"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"SMA-adalah-sebuah-proses-pengumpulan-data-dari-media-sosial-dan-analisanya-untuk-mendapatkan-'insights'-atau-informasi-berharga-untuk-suatu-tujuan-tertentu-(definisi-adopted-dari-Gartner*)\">SMA adalah sebuah proses pengumpulan data dari media sosial dan analisanya untuk mendapatkan &#39;insights&#39; atau informasi berharga untuk suatu tujuan tertentu (definisi diadopsi dari Gartner*).</h3>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/sma.jpg\" style=\"width: 600px; height: 304px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/8_SMA_Cycle.JPG\" style=\"height:300px; width:705px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><img alt=\"\" src=\"img/8_SMA_Techniques.JPG\" style=\"height:400px; width:574px\" /></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Social-Media-Analytics-Challenges\"><u>Tantangan Social Media Analytics</u></h3>\n",
    "\n",
    "<ul>\n",
    "\t<li>\n",
    "\t<p>Pendek (<strong>Short </strong>in lengths): bahkan terkadang tidak mengandung sebuah kalimat yang utuh menurut tata bahasa (grammar).</p>\n",
    "\t</li>\n",
    "\t<li><strong>Noise&nbsp;</strong>: Data media sosial penuh dengan noise seperti typos (salah ketik), encoding yang tidak jamak, slang, dsb.</li>\n",
    "\t<li><strong>Temporal&nbsp;</strong>: Informasi yang sedang trending biasanya hanya sesaat,<br />\n",
    "\tsehingga SMA diharapkan dilakukan dengan cepat menggunakan model-model/teknik-teknik analisa data yang efisien.</li>\n",
    "\t<li><strong>High-dimensional</strong> : Data di Media Sosial (Teks, Gambar, Video, Suara, dsb) adalah data tidak terstruktur berdimensi tinggi.</li>\n",
    "\t<li><strong>Fine-grained</strong> : Data di media sosial berasal dari banyak user yang masing-masingnya bisa jadi membahas beberapa topik yang berbeda.<br />\n",
    "\tSehingga komunitas (kelompok), topik, maupun klasifikasi yang ada menjadi besar (fine-grained).</li>\n",
    "\t<li><strong>Large in volume</strong>&nbsp;&amp; <strong>High velocity</strong>:&nbsp; Data yang sangat besar dan bertambah besar dengan cepat.</li>\n",
    "\t<li><strong>A lot of external Information</strong> : Informasi terkadang lebih banyak terkandung dari luar (eksternal) seperti url website, video, atau hal lain yang dibagikan oleh pengguna media sosial.</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Centrality&nbsp;Analysis</h2>\n",
    "\n",
    "<p>Bertujuan untuk menemukan pengguna yang paling berpengaruh dalam suatu topik pembicaraan di media sosial. Analisanya biasanya dilakukan melalui data graph dari hubungan jaringan pertemanan (follower/friend) antar pengguna atau komunikasi antar pengguna (mentions).</p>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/8_SMA_Centrality.JPG\" style=\"height: 400px ; width: 600px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Community Detection</h2>\n",
    "\n",
    "<p>CD dilakukan pada data jaringan media sosial untuk menemukan komunitas-komunitas dalam pertemanan atau pembicaraan di media sosial. Secara sederhana CD dapat dimengerti sebagai proses clustering (pengelompokan) , namun atas suatu graph.</p>\n",
    "\n",
    "<h2><img alt=\"\" src=\"img/8_SMA_Community.JPG\" style=\"height: 400px ; width: 600px\" /></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study: twitter\n",
    "\n",
    "* Gunakan FireFox untuk menuju ke URL: https://twitter.com/search-advanced\n",
    "* Gunakan sembarang keywords untuk mengambil sampel status media sosial (misal trending topic)\n",
    "* Save as html complete (misal **data.html**)\n",
    "* Upload ke Google Colab\n",
    "\n",
    "<img alt=\"\" src=\"img/6_twitter.png\" style=\"width: 300px; height: 300px;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contoh mengubah html hasil scrapping ke CSV\n",
    "fileSource = 'data.html'\n",
    "fileOutput = 'data.csv'\n",
    "\n",
    "tau.twitter_html2csv(fileSource, fileOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "f = 'data.csv'\n",
    "df = pd.read_csv(f)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tweets = df[' Tweet'].tolist()\n",
    "Tweets[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Usernames = df[' Username'].tolist()\n",
    "Usernames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the Tweet Graph\n",
    "plt.subplots(figsize=(12,8))\n",
    "\n",
    "G = tau.Graph([Usernames,Tweets], Label = False, layOut='spring', plain=True) # layOut = spring, circular, random, shells, spectral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>I. Centrality&nbsp;Analysis</h2>\n",
    "\n",
    "<p>Bertujuan untuk menemukan pengguna yang paling berpengaruh dalam suatu topik pembicaraan di media sosial. Analisanya biasanya dilakukan melalui data graph dari hubungan jaringan pertemanan (follower/friend) antar pengguna atau komunikasi antar pengguna (mentions).</p>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/8_SMA_Centrality.JPG\" style=\"height: 400px ; width: 600px\" /></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Centrality-by-Degree\">Centrality by Degree</h1>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Degree_Centrality.png\" style=\"width: 800px; height: 505px;\" /></p>\n",
    "\n",
    "## Apakah interpretasinya?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's now examine, who are the most \"important\" users in this Graph?\n",
    "Gt = tau.Centrality(G, N=10, method='degree', outliers=False, Label = True, layOut='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau.drawGraph(Gt, True, layOut='circular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"Closeness-Centrality\">Closeness Centrality</h1>\n",
    "\n",
    "<p><img alt=\"\" src=\"img/closeness_centrality.png\" style=\"width: 700px; height: 320px;\" /></p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gt = tau.Centrality(G, N=10, method='closeness', outliers=False, Label = True, layOut='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau.drawGraph(Gt, True, layOut='circular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvector Centrality\n",
    "\n",
    "<p><img alt=\"\" src=\"img/Eigenvector_Centrality_1.png\" style=\"width: 685px; height: 430px;\" /></p>\n",
    "\n",
    "### Digunakan juga oleh Google dalam Algoritma PageRank-nya untuk menentukan halaman web terpenting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gt = tau.Centrality(G, N=10, method='eigen', outliers=False, Label = True, layOut='spring')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau.drawGraph(Gt, True, layOut='circular')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>II. Community Detection (CD)</h2>\n",
    "\n",
    "<p>CD dilakukan pada data jaringan media sosial untuk menemukan komunitas-komunitas dalam pertemanan atau pembicaraan di media sosial. Secara sederhana CD dapat dimengerti sebagai proses \"semacam clustering\" (pengelompokan) , namun atas suatu graph.</p>\n",
    "\n",
    "<img alt=\"\" src=\"img/8_SMA_Community.JPG\" style=\"height: 400px ; width: 600px\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering pada Graph = Community Detection\n",
    "Gt = tau.Community(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penjelasan & Code yang lebih lengkap tentang Centrality & Community Analysis\n",
    "\n",
    "https://tau-data.id/community-detection-centrality/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sebelum dilanjutkan\n",
    "\n",
    "* Unduh \"data.csv\" dari Google Colaboratory (jika belum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Visualisasi</h2>\n",
    "\n",
    "<ul>\n",
    "\t<li>Tidak seperti data terstruktur, data tidak terstruktur seperti teks termasuk salah satu data yang cukup sulit untuk divisualisasikan.<br />\n",
    "\t<img alt=\"\" src=\"img/11_charts.jpg\" style=\"height:150px; width:276px\" /></li>\n",
    "\t<li>Namun terdapat Tools seperti Voyant yang dapat membantu dalam visualisasi sekaligus analisis.<br />\n",
    "\t<img alt=\"\" src=\"img/11_voyant.png\" style=\"height:118px; width:426px\" /></li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Voyant-dapat-digunakan-dalam-2-cara:\">Voyant dapat digunakan dalam 2 cara:</h3>\n",
    "\n",
    "<ol>\n",
    "\t<li>\n",
    "\t<p><strong>Online</strong>:&nbsp;<a href=\"https://voyant-tools.org/\" target=\"_blank\">https://voyant-tools.org/</a><br />\n",
    "\t<u>Kelebihan</u>: Sederhana &amp; portable, tanpa harus install di komputer kita.<br />\n",
    "\t<u>Kekurangan</u>: butuh koneksi internet, tidak cocok untuk data teks yang besar, privacy.</p>\n",
    "\t</li>\n",
    "\t<li>\n",
    "\t<p><strong>Offline </strong>di komputer kita [Java Based]</p>\n",
    "\t</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>[2]. Jalankan Voyant secara offline atau online di URL&nbsp;<a href=\"https://voyant-tools.org/\" target=\"_blank\">https://voyant-tools.org/</a></p>\n",
    "\n",
    "<p>[3]. Upload file yang baru saja kita simpan (data.csv).</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Penggunaan-Voyant-1:-WordClouds\">Penggunaan Voyant 1: WordClouds</h3>\n",
    "\n",
    "<ol>\n",
    "\t<li>Upload teks yang akan di analisa: hasil cluster/ suatu kategori/ topics / raw text.</li>\n",
    "\t<li>slider terms: mengkontrol banyaknya terms yang disertakan.</li>\n",
    "\t<li><strong>Summary </strong>(statistics)</li>\n",
    "\t<li><strong>Documents </strong>==&gt; add more</li>\n",
    "\t<li><strong>Phrases </strong>(n-grams like)</li>\n",
    "\t<li><strong>Export </strong>Visualisasi (kanan atas - pertama)</li>\n",
    "\t<li><strong>Options </strong>(kanan atas ke-3): Font, size, stopwords, whitelist</li>\n",
    "\t<li>&quot;?&quot; ==&gt; More Help</li>\n",
    "</ol>\n",
    "\n",
    "<p>&nbsp;</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Penggunaan-Voyant-2:-Bubbles\">Penggunaan Voyant 2: Bubbles</h3>\n",
    "\n",
    "<ol>\n",
    "\t<li>Upload teks yang akan di analisa: hasil cluster/ suatu kategori/ topics / raw text.<br />\n",
    "\tAtau file yang sudah terupload sebelumnya</li>\n",
    "\t<li>&nbsp;Klik tanda 4-kotak kecil (kanan atas ke-3)</li>\n",
    "\t<li>Pilih Visualization Tools ==&gt; Bubbles</li>\n",
    "\t<li>Option: hanya stopwords</li>\n",
    "\t<li>Export: Hanya PNG</li>\n",
    "</ol>\n",
    "\n",
    "<p>&nbsp;</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Penggunaan-Voyant-3:-Word-Tree\">Penggunaan Voyant 3: Word Tree</h3>\n",
    "\n",
    "<ol>\n",
    "\t<li>Upload teks yang akan di analisa: hasil cluster/ suatu kategori/ topics / raw text.<br />\n",
    "\tAtau file yang sudah terupload sebelumnya</li>\n",
    "\t<li>Klik branch untuk expand</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Penggunaan-Voyant-2:-Bubbles\">Penggunaan Voyant 4: Links</h3>\n",
    "\n",
    "<ol>\n",
    "\t<li>Upload teks yang akan di analisa: hasil cluster/ suatu kategori/ topics / raw text.<br />\n",
    "\tAtau file yang sudah terupload sebelumnya</li>\n",
    "\t<li>Visualization Tools ==&gt; Links</li>\n",
    "\t<li>Klik sembarang terms untuk expand</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Penggunaan-Voyant-5:-Trends\">Penggunaan Voyant 5: Trends</h3>\n",
    "\n",
    "<ol>\n",
    "\t<li>Upload teks yang akan di analisa: hasil cluster/ suatu kategori/ topics / raw text.<br />\n",
    "\tAtau file yang sudah terupload sebelumnya</li>\n",
    "\t<li>Document Tools ==&gt; Trends</li>\n",
    "\t<li>.. Butuh preprocessing ...&nbsp;</li>\n",
    "\t<li>Data harus terurut waktu</li>\n",
    "\t<li>Berikut contohnya</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center><font color=\"blue\"> End of Module 3\n",
    "\n",
    "<hr />\n",
    "<img alt=\"\" src=\"img/6_SocMed_cartoon.png\"/>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
